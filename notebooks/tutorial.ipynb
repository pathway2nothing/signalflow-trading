{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signalflow as sf\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8aabc8",
   "metadata": {},
   "source": [
    "## CORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71749eb8",
   "metadata": {},
   "source": [
    "### Raw Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_store = sf.data.raw_store.DuckDbSpotStore(\n",
    "    db_path=Path(\"test.duckdb\")\n",
    ")\n",
    "\n",
    "loader = sf.data.source.BinanceSpotLoader(\n",
    "    store = spot_store\n",
    ")\n",
    "await loader.download(\n",
    "    pairs=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"BNBUSDT\", \"XRPUSDT\"],\n",
    "    start=datetime(2025, 10, 1),\n",
    "    end=datetime(2025, 12, 31),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed3ed5",
   "metadata": {},
   "source": [
    "### RawDataFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = sf.data.RawDataFactory.from_duckdb_spot_store(\n",
    "    spot_store_path=Path(\"test.duckdb\"),\n",
    "    pairs=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\"],\n",
    "    start=datetime(2025, 10, 1),\n",
    "    end=datetime(2025, 12, 31),\n",
    "    data_types=[\"spot\"],\n",
    ")\n",
    "raw_data_view = sf.core.RawDataView(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedbdeca",
   "metadata": {},
   "source": [
    "## FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b2dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from typing import Any, ClassVar\n",
    "import signalflow as sf\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from typing import ClassVar\n",
    "import signalflow as sf\n",
    "import polars as pl\n",
    "from signalflow.core import SfComponentType, sf_component\n",
    "\n",
    "\n",
    "class RawDataType(str, Enum):\n",
    "    \"\"\"Type of raw market data.\"\"\"\n",
    "    \n",
    "    SPOT = \"spot\"\n",
    "    FUTURES = \"futures\"\n",
    "    PERPETUAL = \"perpetual\"\n",
    "    \n",
    "    @property\n",
    "    def columns(self) -> set[str]:\n",
    "        \"\"\"Columns guaranteed to be present.\"\"\"\n",
    "        base = {\"pair\", \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"}\n",
    "        \n",
    "        if self == RawDataType.FUTURES:\n",
    "            return base | {\"open_interest\"}\n",
    "        elif self == RawDataType.PERPETUAL:\n",
    "            return base | {\"funding_rate\", \"open_interest\"}\n",
    "        \n",
    "        return base\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Feature:\n",
    "    \"\"\"Base class for all features.\n",
    "    \n",
    "    Two methods to implement:\n",
    "        - compute(df): all pairs, abstract for GlobalFeature/Pipeline\n",
    "        - compute_pair(df): one pair, for regular features\n",
    "    \n",
    "    Attributes:\n",
    "        requires: Input column templates, e.g. [\"{price_col}\"]\n",
    "        outputs: Output column templates, e.g. [\"rsi_{period}\"]\n",
    "    \"\"\"\n",
    "    component_type: ClassVar[SfComponentType] = SfComponentType.FEATURE\n",
    "    requires: ClassVar[list[str]] = []\n",
    "    outputs: ClassVar[list[str]] = []\n",
    "    \n",
    "    group_col: str = \"pair\"\n",
    "    ts_col: str = \"timestamp\"\n",
    "    \n",
    "    def compute(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Compute feature for all pairs. Must override.\"\"\"\n",
    "        return df.group_by(self.group_col, maintain_order=True).map_groups(self.compute_pair)\n",
    "    \n",
    "    def compute_pair(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Compute feature for single pair. Override for per-pair features.\"\"\"\n",
    "        raise NotImplementedError(f\"{self.__class__.__name__} must implement compute_pair()\")\n",
    "    \n",
    "    def output_cols(self, prefix: str = \"\") -> list[str]:\n",
    "        \"\"\"Actual output column names with parameter substitution.\"\"\"\n",
    "        return [f\"{prefix}{tpl.format(**self.__dict__)}\" for tpl in self.outputs]\n",
    "    \n",
    "    def required_cols(self) -> list[str]:\n",
    "        \"\"\"Actual required column names with parameter substitution.\"\"\"\n",
    "        return [\n",
    "            tpl.format(**self.__dict__) if \"{\" in tpl else tpl \n",
    "            for tpl in self.requires\n",
    "        ]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "@sf_component(name=\"test_rsi\")\n",
    "class RsiFeature(Feature):\n",
    "    \"\"\"Relative Strength Index.\n",
    "    \n",
    "    Args:\n",
    "        period: RSI period. Default: 14.\n",
    "        price_col: Price column to use. Default: \"close\".\n",
    "    \n",
    "    Example:\n",
    "        >>> rsi = RsiFeature(period=21)\n",
    "        >>> rsi.output_cols()  # [\"rsi_21\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    period: int = 14\n",
    "    price_col: str = \"close\"\n",
    "    \n",
    "    requires = [\"{price_col}\"]\n",
    "    outputs = [\"rsi_{period}\"]\n",
    "    \n",
    "    def compute(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Compute RSI for all pairs.\"\"\"\n",
    "        return df.group_by(self.group_col, maintain_order=True).map_groups(self.compute_pair)\n",
    "    \n",
    "    def compute_pair(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Compute RSI for single pair.\"\"\"\n",
    "        col_name = f\"rsi_{self.period}\"\n",
    "        \n",
    "        delta = pl.col(self.price_col).diff()\n",
    "        gain = pl.when(delta > 0).then(delta).otherwise(0)\n",
    "        loss = pl.when(delta < 0).then(-delta).otherwise(0)\n",
    "        \n",
    "        avg_gain = gain.rolling_mean(window_size=self.period)\n",
    "        avg_loss = loss.rolling_mean(window_size=self.period)\n",
    "        \n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        return df.with_columns(rsi.alias(col_name))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GlobalFeature(Feature):\n",
    "    \"\"\"Base class for features computed across all pairs.\n",
    "    \n",
    "    Override compute() with custom aggregation logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Must override - compute global feature across all pairs.\"\"\"\n",
    "        raise NotImplementedError(f\"{self.__class__.__name__} must implement compute()\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GlobalMeanRsiFeature(GlobalFeature):\n",
    "    \"\"\"Mean RSI across all pairs per timestamp.\n",
    "    \n",
    "    1. Compute RSI per pair\n",
    "    2. Mean across all pairs at time t â†’ global_mean_rsi\n",
    "    3. Optionally: rsi_diff = pair_rsi - global_mean_rsi\n",
    "    \n",
    "    Args:\n",
    "        period: RSI period. Default: 14.\n",
    "        add_diff: Add per-pair difference column. Default: False.\n",
    "    \"\"\"\n",
    "    \n",
    "    period: int = 14\n",
    "    price_col: str = \"close\"\n",
    "    add_diff: bool = False\n",
    "    \n",
    "    requires = [\"{price_col}\"]\n",
    "    outputs = [\"global_mean_rsi_{period}\"]\n",
    "    \n",
    "    def output_cols(self, prefix: str = \"\") -> list[str]:\n",
    "        cols = [f\"{prefix}global_mean_rsi_{self.period}\"]\n",
    "        if self.add_diff:\n",
    "            cols.append(f\"{prefix}rsi_{self.period}_diff\")\n",
    "        return cols\n",
    "    \n",
    "    def compute(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        rsi_col = f\"rsi_{self.period}\"\n",
    "        out_col = f\"global_mean_rsi_{self.period}\"\n",
    "        \n",
    "        # 1. RSI per pair\n",
    "        has_rsi = rsi_col in df.columns\n",
    "        if not has_rsi:\n",
    "            rsi = RsiFeature(period=self.period, price_col=self.price_col)\n",
    "            df = rsi.compute(df)\n",
    "        \n",
    "        # 2. Mean across pairs per timestamp\n",
    "        mean_df = df.group_by(self.ts_col).agg(\n",
    "            pl.col(rsi_col).mean().alias(out_col)\n",
    "        )\n",
    "        \n",
    "        # 3. Join back\n",
    "        df = df.join(mean_df, on=self.ts_col, how=\"left\")\n",
    "        \n",
    "        # 4. Optional diff\n",
    "        if self.add_diff:\n",
    "            df = df.with_columns(\n",
    "                (pl.col(rsi_col) - pl.col(out_col)).alias(f\"rsi_{self.period}_diff\")\n",
    "            )\n",
    "        \n",
    "        # Drop temp RSI if we created it\n",
    "        if not has_rsi:\n",
    "            df = df.drop(rsi_col)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "@dataclass\n",
    "class FeaturePipeline(Feature):\n",
    "    \"\"\"Orchestrates multiple features with optimized execution.\n",
    "    \n",
    "    Groups consecutive per-pair features into batches for single group_by.\n",
    "    \n",
    "    Args:\n",
    "        features: List of features to compute.\n",
    "        raw_data_type: Type of raw data (defines available columns).\n",
    "    \n",
    "    Example:\n",
    "        >>> pipeline = FeaturePipeline(\n",
    "        ...     features=[\n",
    "        ...         RsiFeature(period=14),\n",
    "        ...         SmaFeature(period=20),\n",
    "        ...         GlobalFeature(base=RsiFeature(period=14), reference_pair=\"BTCUSDT\"),\n",
    "        ...     ],\n",
    "        ...     raw_data_type=RawDataType.SPOT,\n",
    "        ... )\n",
    "        >>> df = pipeline.run(raw_data_view)\n",
    "    \"\"\"\n",
    "    \n",
    "    features: list[Feature] = field(default_factory=list)\n",
    "    raw_data_type: RawDataType = RawDataType.SPOT\n",
    "    \n",
    "    requires: ClassVar[list[str]] = []\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if not self.features:\n",
    "            raise ValueError(\"FeaturePipeline requires at least one feature\")\n",
    "        self._validate()\n",
    "    \n",
    "    @property\n",
    "    def outputs(self) -> list[str]:\n",
    "        \"\"\"Aggregated outputs from all features.\"\"\"\n",
    "        result = []\n",
    "        for f in self.features:\n",
    "            result.extend(f.output_cols())\n",
    "        return result\n",
    "    \n",
    "    def output_cols(self, prefix: str = \"\") -> list[str]:\n",
    "        return [f\"{prefix}{col}\" for col in self.outputs]\n",
    "    \n",
    "    def _validate(self):\n",
    "        \"\"\"Validate all dependencies are satisfied.\"\"\"\n",
    "        available = self.raw_data_type.columns.copy()\n",
    "        \n",
    "        for f in self.features:\n",
    "            required = set(f.required_cols())\n",
    "            missing = required - available\n",
    "            \n",
    "            if missing:\n",
    "                raise ValueError(\n",
    "                    f\"{f.__class__.__name__} requires {missing}, \"\n",
    "                    f\"available: {sorted(available)}\"\n",
    "                )\n",
    "            \n",
    "            available.update(f.output_cols())\n",
    "    \n",
    "    def _group_into_batches(self) -> list[list[Feature]]:\n",
    "        \"\"\"Group features: consecutive per-pair â†’ batch, global â†’ separate.\"\"\"\n",
    "        batches = []\n",
    "        current_batch = []\n",
    "        \n",
    "        for f in self.features:\n",
    "            is_global = isinstance(f, (GlobalFeature, GlobalMeanRsiFeature, FeaturePipeline))\n",
    "            \n",
    "            if is_global:\n",
    "                if current_batch:\n",
    "                    batches.append(current_batch)\n",
    "                    current_batch = []\n",
    "                batches.append([f])\n",
    "            else:\n",
    "                current_batch.append(f)\n",
    "        if current_batch:\n",
    "            batches.append(current_batch)\n",
    "        \n",
    "        return batches\n",
    "    \n",
    "    def _is_per_pair_batch(self, batch: list[Feature]) -> bool:\n",
    "        \"\"\"Check if batch contains only per-pair features.\"\"\"\n",
    "        return not any(\n",
    "            isinstance(f, (GlobalFeature, GlobalMeanRsiFeature, FeaturePipeline)) \n",
    "            for f in batch\n",
    "        )\n",
    "    \n",
    "    def compute(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Compute all features with optimized batching.\"\"\"\n",
    "        df = df.sort([self.group_col, self.ts_col])\n",
    "        \n",
    "        batches = self._group_into_batches()\n",
    "        \n",
    "        for batch in batches:\n",
    "            if self._is_per_pair_batch(batch):\n",
    "                def apply_batch(pair_df: pl.DataFrame, features=batch) -> pl.DataFrame:\n",
    "                    for f in features:\n",
    "                        pair_df = f.compute_pair(pair_df)\n",
    "                    return pair_df\n",
    "                \n",
    "                df = df.group_by(self.group_col, maintain_order=True).map_groups(apply_batch)\n",
    "            else:\n",
    "                for f in batch:\n",
    "                    df = f.compute(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def run(self, raw_data_view: sf.RawDataView) -> pl.DataFrame:\n",
    "        \"\"\"Entry point: load from RawDataView and compute.\"\"\"\n",
    "        df = raw_data_view.to_polars(self.raw_data_type)\n",
    "        return self.compute(df)\n",
    "    \n",
    "    def to_mermaid(self) -> str:\n",
    "        \"\"\"Generate Mermaid diagram of feature dependencies.\"\"\"\n",
    "        lines = [\"graph LR\"]\n",
    "        lines.append(\"    subgraph Input\")\n",
    "        for col in sorted(self.raw_data_type.columns):\n",
    "            lines.append(f\"        {col}[{col}]\")\n",
    "        lines.append(\"    end\")\n",
    "        \n",
    "        for f in self.features:\n",
    "            name = f.__class__.__name__\n",
    "            if hasattr(f, 'period'):\n",
    "                name = f\"{name}_{f.period}\"\n",
    "            \n",
    "            for req in f.required_cols():\n",
    "                lines.append(f\"    {req} --> {name}\")\n",
    "            for out in f.output_cols():\n",
    "                lines.append(f\"    {name} --> {out}[{out}]\")\n",
    "        \n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "pipeline = FeaturePipeline(\n",
    "    features=[\n",
    "        RsiFeature(period=14),\n",
    "        RsiFeature(period=21),\n",
    "    ],\n",
    "    raw_data_type=RawDataType.SPOT,\n",
    ")\n",
    "\n",
    "df = pipeline.run(raw_data_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fc4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6aba86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26401716",
   "metadata": {},
   "outputs": [],
   "source": [
    "abdlfds;f,dlsafgmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1219e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import polars as pl\n",
    "\n",
    "@dataclass\n",
    "@sf.core.sf_component(name='custom/log_return', override=True)\n",
    "class LogReturnExtractor(sf.feature.FeatureExtractor):\n",
    "    \"\"\"Calculates logarithmic returns: ln(Pt / Pt-1).\"\"\"\n",
    "    \n",
    "    price_col: str = 'close'\n",
    "    out_col: str = 'log_ret'\n",
    "    period: int = 1\n",
    "\n",
    "    def compute_group(self, group_df: pl.DataFrame, data_context: dict | None) -> pl.DataFrame:\n",
    "        if self.price_col not in group_df.columns:\n",
    "            raise ValueError(f\"Missing required column: {self.price_col}\")\n",
    "\n",
    "        log_ret = (\n",
    "            pl.col(self.price_col)\n",
    "            .log()\n",
    "            .diff(n=self.period)\n",
    "            .alias(self.out_col)\n",
    "        )\n",
    "        \n",
    "        return group_df.with_columns(log_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = sf.feature.FeatureSet(\n",
    "    extractors=[\n",
    "        LogReturnExtractor(price_col=\"close\", out_col=\"log_ret_1\", period=1), \n",
    "        LogReturnExtractor(price_col=\"close\", out_col=\"log_ret_2\", period=2), \n",
    "        LogReturnExtractor(price_col=\"close\", out_col=\"log_ret_4\", period=4), \n",
    "        LogReturnExtractor(price_col=\"close\", out_col=\"log_ret_8\", period=8), \n",
    "        LogReturnExtractor(price_col=\"close\", out_col=\"log_ret_16\", period=16), \n",
    "        LogReturnExtractor(price_col=\"close\", out_col=\"log_ret_32\", period=32), \n",
    "    ]\n",
    ")\n",
    "features_df = feature_set.extract(raw_data_view)\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52874e5",
   "metadata": {},
   "source": [
    "## DETECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45381502",
   "metadata": {},
   "source": [
    "### Custom Signal Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8995f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "@sf.core.sf_component(name='momentum_breakout', override=True)\n",
    "class MomentumDetector(sf.detector.SignalDetector):\n",
    "    \"\"\"Detects large price moves based on log return thresholds.\"\"\"\n",
    "    \n",
    "    threshold: float = 0.02 \n",
    "    feature_col: str = 'log_ret'\n",
    "    price_col: str = 'close'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.feature_set = sf.feature.FeatureSet(extractors=[\n",
    "            LogReturnExtractor(\n",
    "                price_col=self.price_col, \n",
    "                out_col=self.feature_col,\n",
    "                period=1\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def detect(self, features: pl.DataFrame, context: dict | None = None) -> sf.core.Signals:\n",
    "        feat = pl.col(self.feature_col)\n",
    "        \n",
    "        signal_type = (\n",
    "            pl.when(feat > self.threshold).then(pl.lit(sf.core.SignalType.RISE.value))\n",
    "            .when(feat < -self.threshold).then(pl.lit(sf.core.SignalType.FALL.value))\n",
    "            .otherwise(pl.lit(sf.core.SignalType.NONE.value))\n",
    "            .alias('signal_type')\n",
    "        )\n",
    "        \n",
    "        signal_val = (\n",
    "            pl.when(feat > self.threshold).then(1)\n",
    "            .when(feat < -self.threshold).then(-1)\n",
    "            .otherwise(0)\n",
    "            .alias('signal')\n",
    "        )\n",
    "\n",
    "        df = features.with_columns([signal_type, signal_val])\n",
    "        \n",
    "        out = df.filter(pl.col('signal_type') != sf.core.SignalType.NONE.value)\n",
    "        \n",
    "        return sf.core.Signals(out.select([self.pair_col, self.ts_col, 'signal_type', 'signal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detector = MomentumDetector(threshold=0.01)\n",
    "\n",
    "print(\"--- Running Pipeline ---\")\n",
    "signals = detector.run(raw_data_view)\n",
    "\n",
    "print(f\"\\nDetected {signals.value.height} signals:\")\n",
    "display(signals.value)\n",
    "\n",
    "print(\"\\nVerifying with Source Data:\")\n",
    "dates_of_interest = signals.value.get_column(\"timestamp\")\n",
    "spot_df = raw_data.get(\"spot\")\n",
    "\n",
    "verification = spot_df.filter(pl.col(\"timestamp\").is_in(dates_of_interest))\n",
    "display(verification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c95dae",
   "metadata": {},
   "source": [
    "### Result ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe57f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "import plotly.io as pio\n",
    "\n",
    "def plot_signals(raw_df: pl.DataFrame, signals_df: pl.DataFrame, pair: str = \"BTCUSDT\"):\n",
    "\n",
    "    price_data = raw_df.select([\"timestamp\", \"pair\", \"close\"]).filter(pl.col(\"pair\") == pair)\n",
    "    sig_data = signals_df.select([\"timestamp\", \"pair\", \"signal\"]).filter(pl.col(\"pair\") == pair)\n",
    "\n",
    "    price_data = price_data.with_columns(pl.col(\"timestamp\").cast(pl.Datetime(\"us\")))\n",
    "    sig_data = sig_data.with_columns(pl.col(\"timestamp\").cast(pl.Datetime(\"us\")))\n",
    "\n",
    "    df_plot = price_data.sort(\"timestamp\").to_pandas()\n",
    "    signals_with_price = sig_data.join(price_data, on=[\"timestamp\", \"pair\"], how=\"inner\")\n",
    "    sig_plot = signals_with_price.to_pandas()\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_plot['timestamp'], \n",
    "        y=df_plot['close'], \n",
    "        mode='lines', \n",
    "        name=f'{pair} Price',\n",
    "        line=dict(color='#2E86C1', width=1.5) \n",
    "    ))\n",
    "\n",
    "    buys = sig_plot[sig_plot['signal'] == 1]\n",
    "    if not buys.empty:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=buys['timestamp'],\n",
    "            y=buys['close'],\n",
    "            mode='markers',\n",
    "            name='Buy Signal',\n",
    "            marker=dict(symbol='triangle-up', size=13, color='#00CC96', line=dict(width=1, color='black'))\n",
    "        ))\n",
    "\n",
    "    sells = sig_plot[sig_plot['signal'] == -1]\n",
    "    if not sells.empty:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=sells['timestamp'],\n",
    "            y=sells['close'],\n",
    "            mode='markers',\n",
    "            name='Sell Signal',\n",
    "            marker=dict(symbol='triangle-down', size=13, color='#EF553B', line=dict(width=1, color='black'))\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(text=f'SignalFlow: {pair} Analysis', font=dict(color='black')),\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price',\n",
    "        template='plotly_white', \n",
    "        hovermode='x unified',\n",
    "        height=600,\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray')\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "spot_df = raw_data.get(\"spot\")\n",
    "fig = plot_signals(spot_df, signals.value, pair=\"ETHUSDT\")\n",
    "fig.write_image(\"spot_signals.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5348f9",
   "metadata": {},
   "source": [
    "## VALIDATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46661fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from signalflow.target import FixedHorizonLabeler\n",
    "\n",
    "\n",
    "labeler = FixedHorizonLabeler(\n",
    "    price_col='close', \n",
    "    horizon=10, \n",
    "    include_meta=True \n",
    ")\n",
    "labeled_df = labeler.compute(\n",
    "    df=raw_data_view.to_polars(\"spot\"),\n",
    "    signals=signals \n",
    ")\n",
    "\n",
    "print(\"Labeled Data Sample (Signals only):\")\n",
    "labeled_signals = labeled_df.filter(pl.col(\"label\") != \"none\")\n",
    "display(labeled_signals.select([\"timestamp\", \"label\", \"ret\"]).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from signalflow.validator import SklearnSignalValidator\n",
    "\n",
    "validator = SklearnSignalValidator(\n",
    "    model_type='random_forest',\n",
    "    model_params={'n_estimators': 100, 'max_depth': 5, 'random_state': 42}\n",
    ")\n",
    "\n",
    "\n",
    "features_df = detector.preprocess(raw_data_view)\n",
    "\n",
    "split_idx = int(features_df.height * 0.8)\n",
    "X_train = features_df.slice(0, split_idx)\n",
    "X_test = features_df.slice(split_idx, None)\n",
    "\n",
    "y = labeled_df.select(\"label\")\n",
    "y_train = y.slice(0, split_idx)\n",
    "y_test = y.slice(split_idx, None)\n",
    "\n",
    "print(\"--- Training Validator ---\")\n",
    "validator.fit(X_train, y_train)\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6706100",
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_signals = validator.validate_signals(signals, features_df)\n",
    "\n",
    "print(\"\\nValidated Signals (with probabilities):\")\n",
    "display(\n",
    "    validated_signals.value\n",
    "    .select([\n",
    "        \"timestamp\", \n",
    "        \"signal_type\", \n",
    "        \"probability_rise\", \n",
    "        \"probability_fall\"\n",
    "    ])\n",
    "    .sort(\"probability_rise\", descending=True)\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f94f3",
   "metadata": {},
   "source": [
    "### Visualizing Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba48d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "import signalflow as sf \n",
    "\n",
    "def plot_strategy_complete(raw_df: pl.DataFrame, val_signals: sf.core.Signals, pair: str = \"BTCUSDT\"):\n",
    "    raw_sorted = raw_df.filter(pl.col(\"pair\") == pair).sort(\"timestamp\")\n",
    "    raw_sorted = raw_sorted.with_columns(pl.col(\"timestamp\").cast(pl.Datetime(\"us\")))\n",
    "    df_plot = raw_sorted.to_pandas()\n",
    "    \n",
    "    sig_data = val_signals.value.filter(pl.col(\"pair\") == pair)\n",
    "    sig_data = sig_data.with_columns(pl.col(\"timestamp\").cast(pl.Datetime(\"us\")))\n",
    "    \n",
    "    merged = sig_data.join(raw_sorted.select([\"timestamp\", \"close\"]), on=\"timestamp\", how=\"inner\").to_pandas()\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_plot['timestamp'], \n",
    "        y=df_plot['close'], \n",
    "        mode='lines', \n",
    "        name='Price', \n",
    "        line=dict(color='#2962FF', width=1.5) \n",
    "    ))\n",
    "\n",
    "\n",
    "    buys = merged[merged['signal_type'] == 'rise']\n",
    "    \n",
    "    if not buys.empty:\n",
    "        buys_noise = buys[buys['probability_rise'] < 0.5]\n",
    "        if not buys_noise.empty:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=buys_noise['timestamp'], y=buys_noise['close'],\n",
    "                mode='markers', name='Buy (Ignored)',\n",
    "                marker=dict(\n",
    "                    symbol='triangle-up', \n",
    "                    size=8, \n",
    "                    color='#B0BEC5', \n",
    "                    line=dict(width=1, color='gray')\n",
    "                ),\n",
    "                hovertemplate=\"<b>Buy (Ignored)</b><br>Price: %{y:.2f}<br>Conf: %{text}<extra></extra>\",\n",
    "                text=[f\"{p:.2f}\" for p in buys_noise['probability_rise']]\n",
    "            ))\n",
    "\n",
    "        buys_signal = buys[buys['probability_rise'] >= 0.5]\n",
    "        if not buys_signal.empty:\n",
    "            sizes = 12 + (buys_signal['probability_rise'] * 15)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=buys_signal['timestamp'], y=buys_signal['close'],\n",
    "                mode='markers', name='Buy (Active)',\n",
    "                marker=dict(\n",
    "                    symbol='triangle-up', \n",
    "                    size=sizes, \n",
    "                    color=buys_signal['probability_rise'],\n",
    "                    colorscale=[[0, '#B9F6CA'], [1, '#00C853']], \n",
    "                    cmin=0.5, cmax=1.0, \n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Buy Conf\", x=1.02, len=0.4, y=0.8),\n",
    "                    line=dict(width=1, color='black')\n",
    "                ),\n",
    "                hovertemplate=\"<b>Buy (Active)</b><br>Price: %{y:.2f}<br>Conf: %{text}<extra></extra>\",\n",
    "                text=[f\"{p:.2f}\" for p in buys_signal['probability_rise']]\n",
    "            ))\n",
    "\n",
    "\n",
    "    sells = merged[merged['signal_type'] == 'fall']\n",
    "    \n",
    "    if not sells.empty:\n",
    "        sells_noise = sells[sells['probability_fall'] < 0.5]\n",
    "        if not sells_noise.empty:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=sells_noise['timestamp'], y=sells_noise['close'],\n",
    "                mode='markers', name='Sell (Ignored)',\n",
    "                marker=dict(\n",
    "                    symbol='triangle-down', \n",
    "                    size=8, \n",
    "                    color='#B0BEC5', \n",
    "                    line=dict(width=1, color='gray')\n",
    "                ),\n",
    "                hovertemplate=\"<b>Sell (Ignored)</b><br>Price: %{y:.2f}<br>Conf: %{text}<extra></extra>\",\n",
    "                text=[f\"{p:.2f}\" for p in sells_noise['probability_fall']]\n",
    "            ))\n",
    "\n",
    "        sells_signal = sells[sells['probability_fall'] >= 0.5]\n",
    "        if not sells_signal.empty:\n",
    "            sizes = 12 + (sells_signal['probability_fall'] * 15)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=sells_signal['timestamp'], y=sells_signal['close'],\n",
    "                mode='markers', name='Sell (Active)',\n",
    "                marker=dict(\n",
    "                    symbol='triangle-down', \n",
    "                    size=sizes, \n",
    "                    color=sells_signal['probability_fall'],\n",
    "                    colorscale=[[0, '#EF9A9A'], [1, '#C62828']], \n",
    "                    cmin=0.5, cmax=1.0,\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Sell Conf\", x=1.02, len=0.4, y=0.2),\n",
    "                    line=dict(width=1, color='black')\n",
    "                ),\n",
    "                hovertemplate=\"<b>Sell (Active)</b><br>Price: %{y:.2f}<br>Conf: %{text}<extra></extra>\",\n",
    "                text=[f\"{p:.2f}\" for p in sells_signal['probability_fall']]\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(text=f'AI Strategy Analysis: {pair}', font=dict(size=20, color='#333')),\n",
    "        template='plotly_white',\n",
    "        height=700,\n",
    "        hovermode='x unified',\n",
    "        xaxis=dict(showgrid=True, gridcolor='#eceff1'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='#eceff1'),\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0)\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "plot_strategy_complete(raw_data_view.to_polars(\"spot\"), validated_signals, pair=\"SOLUSDT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbee15b",
   "metadata": {},
   "source": [
    "## STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ee400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from signalflow.strategy.broker import BacktestBroker\n",
    "from signalflow.strategy.broker.executor import VirtualSpotExecutor\n",
    "from signalflow.data.strategy_store import DuckDbStrategyStore\n",
    "from signalflow.strategy.runner import BacktestRunner, OptimizedBacktestRunner\n",
    "from signalflow.strategy.component.entry import SignalEntryRule\n",
    "from signalflow.strategy.component.exit import TakeProfitStopLossExit\n",
    "from signalflow.analytic.strategy import TotalReturnMetric, BalanceAllocationMetric, DrawdownMetric, WinRateMetric, SharpeRatioMetric\n",
    "\n",
    "strategy_store = DuckDbStrategyStore(\"strategy.duckdb\")\n",
    "strategy_store.init()\n",
    "\n",
    "executor = VirtualSpotExecutor(fee_rate=0.001, slippage_pct=0.001) \n",
    "broker = BacktestBroker(executor=executor, store=strategy_store)\n",
    "\n",
    "entry_rule = SignalEntryRule(\n",
    "    base_position_size=1000.0,  \n",
    "    use_probability_sizing=True, \n",
    "    min_probability=0.6,         \n",
    "    max_positions_per_pair=1,\n",
    "    allow_shorts=False        \n",
    ")\n",
    "\n",
    "exit_rule = TakeProfitStopLossExit(\n",
    "    take_profit_pct=0.02, \n",
    "    stop_loss_pct=0.02    \n",
    ")\n",
    "\n",
    "metrics=[\n",
    "        TotalReturnMetric(initial_capital=10000.0),\n",
    "        BalanceAllocationMetric(initial_capital=10000.0),\n",
    "        DrawdownMetric(),\n",
    "        WinRateMetric(),\n",
    "        SharpeRatioMetric(initial_capital=10000.0, window_size=100)\n",
    "]\n",
    "\n",
    "runner = OptimizedBacktestRunner(\n",
    "    strategy_id=\"ml_momentum_strategy\",\n",
    "    broker=broker,\n",
    "    entry_rules=[entry_rule],\n",
    "    exit_rules=[exit_rule],\n",
    "    metrics=metrics,\n",
    "    initial_capital=10000.0,\n",
    "    data_key=\"spot\" \n",
    ")\n",
    "\n",
    "print(\"--- Running Backtest ---\")\n",
    "final_state = runner.run(raw_data, validated_signals)\n",
    "\n",
    "results = runner.get_results()\n",
    "print(f\"\\nFinal Equity: ${results['final_equity']:.2f}\")\n",
    "print(f\"Total Return: {results['final_return']*100:.2f}%\")\n",
    "print(f\"Trades Executed: {results['total_trades']}\")\n",
    "\n",
    "\n",
    "print(\"Recent Trades:\")\n",
    "display(results['trades_df'].tail(10))\n",
    "\n",
    "metrics_df = results['metrics_df']\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203867a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def plot_backtest_performance(results: dict):\n",
    "\n",
    "    metrics_df = results.get('metrics_df')\n",
    "    \n",
    "    if metrics_df is None or metrics_df.height == 0:\n",
    "        print(\"No metrics to plot\")\n",
    "        return\n",
    "    \n",
    "    if 'timestamp' in metrics_df.columns:\n",
    "        timestamps = metrics_df.select(\n",
    "            pl.from_epoch(pl.col('timestamp').cast(pl.Int64), time_unit='s').alias('datetime')\n",
    "        ).get_column('datetime').to_list()\n",
    "    else:\n",
    "        timestamps = list(range(metrics_df.height))\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=(\n",
    "            'Strategy Performance', \n",
    "            'Position Metrics',\n",
    "            'Balance Allocation'\n",
    "        ),\n",
    "        row_heights=[0.45, 0.30, 0.25]\n",
    "    )\n",
    "\n",
    "    \n",
    "    if 'total_return' in metrics_df.columns:\n",
    "        returns_pct = (metrics_df.get_column('total_return') * 100).to_list()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=returns_pct,\n",
    "                mode='lines',\n",
    "                name='Strategy Return',\n",
    "                line=dict(color='#1E88E5', width=2.5),\n",
    "                hovertemplate='Return: %{y:.2f}%<extra></extra>'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    fig.add_hline(\n",
    "        y=0, \n",
    "        line_dash=\"dash\", \n",
    "        line_color=\"#9E9E9E\", \n",
    "        line_width=1,\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    if 'open_positions' in metrics_df.columns:\n",
    "        open_pos = metrics_df.get_column('open_positions').to_list()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=open_pos,\n",
    "                mode='lines',\n",
    "                name='Open Positions',\n",
    "                line=dict(color='#43A047', width=2),\n",
    "                fill='tozeroy',\n",
    "                fillcolor='rgba(67, 160, 71, 0.15)',\n",
    "                hovertemplate='Open: %{y}<extra></extra>'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    if 'closed_positions' in metrics_df.columns:\n",
    "        closed_pos = metrics_df.get_column('closed_positions').to_list()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=closed_pos,\n",
    "                mode='lines',\n",
    "                name='Closed Positions',\n",
    "                line=dict(color='#8E24AA', width=1.5, dash='dot'),\n",
    "                hovertemplate='Closed: %{y}<extra></extra>'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "\n",
    "    if 'cash' in metrics_df.columns and 'equity' in metrics_df.columns:\n",
    "        cash = metrics_df.get_column('cash').to_list()\n",
    "        equity = metrics_df.get_column('equity').to_list()\n",
    "        \n",
    "        initial_capital = results.get('initial_capital', equity[0] if equity else 10000)\n",
    "        \n",
    "        allocated_pct = [(eq - c) / eq if eq > 0 else 0 for eq, c in zip(equity, cash)]\n",
    "        free_pct = [c / eq if eq > 0 else 0 for eq, c in zip(equity, cash)]\n",
    "        \n",
    "        total_balance_pct = [(eq / initial_capital - 1) * 100 for eq in equity]\n",
    "        \n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=free_pct,\n",
    "                mode='lines',\n",
    "                name='Free Cash',\n",
    "                line=dict(width=0),\n",
    "                fillcolor='rgba(100, 181, 246, 0.6)', \n",
    "                fill='tozeroy',\n",
    "                stackgroup='balance',\n",
    "                hovertemplate='Free: %{y:.1%}<extra></extra>'\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=allocated_pct,\n",
    "                mode='lines',\n",
    "                name='In Positions',\n",
    "                line=dict(width=0),\n",
    "                fillcolor='rgba(25, 118, 210, 0.7)',  \n",
    "                fill='tonexty',\n",
    "                stackgroup='balance',\n",
    "                hovertemplate='Allocated: %{y:.1%}<extra></extra>'\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=total_balance_pct,\n",
    "                mode='lines',\n",
    "                name='Total Return',\n",
    "                line=dict(color='#1565C0', width=2.5),\n",
    "                yaxis='y4', \n",
    "                hovertemplate='Total: %{y:.2f}%<extra></extra>'\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    " \n",
    "    final_return = results.get('final_return', 0) * 100\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f'Backtest Results | Total Return: {final_return:.2f}%',\n",
    "            font=dict(size=18, color='#212121')\n",
    "        ),\n",
    "        template='plotly_white',\n",
    "        height=900,\n",
    "        hovermode='x unified',\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            yanchor='bottom',\n",
    "            y=1.01,\n",
    "            xanchor='left',\n",
    "            x=0,\n",
    "            font=dict(size=11)\n",
    "        ),\n",
    "        showlegend=True,\n",
    "        plot_bgcolor='#FAFAFA',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text='Date', row=3, col=1)\n",
    "    fig.update_yaxes(title_text='Return (%)', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Count', row=2, col=1)\n",
    "    fig.update_yaxes(\n",
    "        title_text='Allocation', \n",
    "        row=3, col=1, \n",
    "        tickformat='.0%',\n",
    "        range=[0, 1] \n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        yaxis4=dict(\n",
    "            title='Total Return (%)',\n",
    "            overlaying='y3',\n",
    "            side='right',\n",
    "            showgrid=False\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        showgrid=True, \n",
    "        gridwidth=1, \n",
    "        gridcolor='#E0E0E0',\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor='#BDBDBD'\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showgrid=True, \n",
    "        gridwidth=1, \n",
    "        gridcolor='#E0E0E0',\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor='#BDBDBD'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_detailed_metrics(results: dict):\n",
    "\n",
    "    metrics_df = results.get('metrics_df')\n",
    "    \n",
    "    if metrics_df is None or metrics_df.height == 0:\n",
    "        print(\"No metrics to plot\")\n",
    "        return\n",
    "    \n",
    "    if 'timestamp' in metrics_df.columns:\n",
    "        timestamps = metrics_df.select(\n",
    "            pl.from_epoch(pl.col('timestamp').cast(pl.Int64), time_unit='s').alias('datetime')\n",
    "        ).get_column('datetime').to_list()\n",
    "    else:\n",
    "        timestamps = list(range(metrics_df.height))\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.08,\n",
    "        subplot_titles=('Drawdown Analysis', 'Capital Utilization'),\n",
    "        row_heights=[0.6, 0.4]\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    if 'current_drawdown' in metrics_df.columns:\n",
    "        drawdown = metrics_df.get_column('current_drawdown').to_list()\n",
    "        drawdown_pct = [-d * 100 for d in drawdown]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=drawdown_pct,\n",
    "                mode='lines',\n",
    "                name='Drawdown',\n",
    "                line=dict(color='#E53935', width=2),\n",
    "                fill='tozeroy',\n",
    "                fillcolor='rgba(229, 57, 53, 0.2)',\n",
    "                hovertemplate='DD: %{y:.2f}%<extra></extra>'\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        max_dd = results.get('max_drawdown', 0) * 100\n",
    "        if max_dd > 0:\n",
    "            fig.add_hline(\n",
    "                y=-max_dd,\n",
    "                line_dash=\"dash\",\n",
    "                line_color=\"#C62828\",\n",
    "                line_width=1.5,\n",
    "                annotation_text=f\"Max DD: {max_dd:.2f}%\",\n",
    "                annotation_position=\"right\",\n",
    "                row=1, col=1\n",
    "            )\n",
    "    \n",
    "    \n",
    "    if 'capital_utilization' in metrics_df.columns:\n",
    "        util = metrics_df.get_column('capital_utilization').to_list()\n",
    "        util_pct = [u * 100 for u in util]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=timestamps,\n",
    "                y=util_pct,\n",
    "                mode='lines',\n",
    "                name='Capital Utilization',\n",
    "                line=dict(color='#FB8C00', width=2),\n",
    "                fill='tozeroy',\n",
    "                fillcolor='rgba(251, 140, 0, 0.15)',\n",
    "                hovertemplate='Util: %{y:.1f}%<extra></extra>'\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        fig.add_hline(\n",
    "            y=100,\n",
    "            line_dash=\"dot\",\n",
    "            line_color=\"#9E9E9E\",\n",
    "            line_width=1,\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=600,\n",
    "        hovermode='x unified',\n",
    "        showlegend=True,\n",
    "        plot_bgcolor='#FAFAFA',\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "    \n",
    "    fig.update_yaxes(title_text='Drawdown (%)', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Utilization (%)', row=2, col=1)\n",
    "    fig.update_xaxes(title_text='Date', row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#E0E0E0')\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#E0E0E0')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def print_performance_summary(results: dict):\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ðŸ“Š BACKTEST PERFORMANCE SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Performance metrics\n",
    "    final_return = results.get('final_return', 0) * 100\n",
    "    max_dd = results.get('max_drawdown', 0) * 100\n",
    "    sharpe = results.get('sharpe_ratio', 0)\n",
    "    \n",
    "    print(f\"\\nðŸ’° Returns:\")\n",
    "    print(f\"   Total Return:     {final_return:>8.2f}%\")\n",
    "    print(f\"   Max Drawdown:     {max_dd:>8.2f}%\")\n",
    "    print(f\"   Sharpe Ratio:     {sharpe:>8.3f}\")\n",
    "    \n",
    "    if abs(max_dd) > 0.01:\n",
    "        calmar = final_return / abs(max_dd)\n",
    "        print(f\"   Calmar Ratio:     {calmar:>8.3f}\")\n",
    "    \n",
    "    total_trades = results.get('total_trades', 0)\n",
    "    entry_count = results.get('entry_count', 0)\n",
    "    exit_count = results.get('exit_count', 0)\n",
    "    win_rate = results.get('win_rate', 0) * 100 if 'win_rate' in results else 0\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Trading Activity:\")\n",
    "    print(f\"   Total Trades:     {total_trades:>8}\")\n",
    "    print(f\"   Entry Trades:     {entry_count:>8}\")\n",
    "    print(f\"   Exit Trades:      {exit_count:>8}\")\n",
    "    if win_rate > 0:\n",
    "        print(f\"   Win Rate:         {win_rate:>8.1f}%\")\n",
    "    \n",
    "    final_equity = results.get('final_equity', 0)\n",
    "    initial_capital = results.get('initial_capital', 10000)\n",
    "    \n",
    "    print(f\"\\nðŸ’µ Capital:\")\n",
    "    print(f\"   Initial:          ${initial_capital:>12,.2f}\")\n",
    "    print(f\"   Final:            ${final_equity:>12,.2f}\")\n",
    "    print(f\"   Profit/Loss:      ${final_equity - initial_capital:>12,.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "results = runner.get_results()\n",
    "\n",
    "print_performance_summary(results)\n",
    "\n",
    "fig1 = plot_backtest_performance(results)\n",
    "pio.write_image(fig1, \"backtest_performance.png\") \n",
    "\n",
    "fig1.show()\n",
    "\n",
    "fig2 = plot_detailed_metrics(results)\n",
    "pio.write_image(fig2, \"detailed_metrics.png\") \n",
    "\n",
    "fig2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signalflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
