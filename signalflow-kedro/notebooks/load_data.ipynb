{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923be6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Binance OHLCV data loader with DuckDB storage.\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import duckdb\n",
    "import polars as pl\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BinanceClient:\n",
    "    \"\"\"Async client for Binance REST API.\"\"\"\n",
    "    \n",
    "    base_url: str = \"https://api.binance.com\"\n",
    "    max_retries: int = 3\n",
    "    _session: Optional[aiohttp.ClientSession] = field(default=None, init=False)\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        timeout = aiohttp.ClientTimeout(total=30)\n",
    "        self._session = aiohttp.ClientSession(timeout=timeout)\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, *args):\n",
    "        if self._session:\n",
    "            await self._session.close()\n",
    "    \n",
    "    async def get_klines(\n",
    "        self,\n",
    "        symbol: str,\n",
    "        timeframe: str = \"1m\",\n",
    "        start_time: Optional[datetime] = None,\n",
    "        end_time: Optional[datetime] = None,\n",
    "        limit: int = 1000\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"Fetches OHLCV data from Binance.\n",
    "        \n",
    "        Args:\n",
    "            symbol: Trading pair (e.g., 'BTCUSDT').\n",
    "            timeframe: Candle interval ('1m', '5m', '15m', '1h', '4h', '1d').\n",
    "            start_time: Start of the range.\n",
    "            end_time: End of the range.\n",
    "            limit: Max candles per request (max 1000).\n",
    "        \n",
    "        Returns:\n",
    "            List of OHLCV dictionaries.\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": timeframe,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "        if start_time:\n",
    "            params[\"startTime\"] = int(start_time.timestamp() * 1000)\n",
    "        if end_time:\n",
    "            params[\"endTime\"] = int(end_time.timestamp() * 1000)\n",
    "        \n",
    "        url = f\"{self.base_url}/api/v3/klines\"\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                async with self._session.get(url, params=params) as resp:\n",
    "                    if resp.status == 429:\n",
    "                        retry_after = int(resp.headers.get(\"Retry-After\", 60))\n",
    "                        logger.warning(f\"Rate limited, waiting {retry_after}s\")\n",
    "                        await asyncio.sleep(retry_after)\n",
    "                        continue\n",
    "                    \n",
    "                    if resp.status != 200:\n",
    "                        text = await resp.text()\n",
    "                        raise Exception(f\"Binance API error {resp.status}: {text}\")\n",
    "                    \n",
    "                    data = await resp.json()\n",
    "                    break\n",
    "                    \n",
    "            except aiohttp.ClientError as e:\n",
    "                if attempt < self.max_retries - 1:\n",
    "                    wait = 2 ** attempt\n",
    "                    logger.warning(f\"Request failed, retrying in {wait}s: {e}\")\n",
    "                    await asyncio.sleep(wait)\n",
    "                else:\n",
    "                    raise\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                \"timestamp\": datetime.fromtimestamp(int(k[6]) / 1000),\n",
    "                \"open\": float(k[1]),\n",
    "                \"high\": float(k[2]),\n",
    "                \"low\": float(k[3]),\n",
    "                \"close\": float(k[4]),\n",
    "                \"volume\": float(k[7]),\n",
    "                \"trades\": int(k[8]),\n",
    "            }\n",
    "            for k in data\n",
    "        ]\n",
    "    \n",
    "    async def get_klines_range(\n",
    "        self,\n",
    "        symbol: str,\n",
    "        timeframe: str,\n",
    "        start_time: datetime,\n",
    "        end_time: datetime,\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"Downloads all klines for a specified period with pagination.\n",
    "        \n",
    "        Args:\n",
    "            symbol: Trading pair.\n",
    "            timeframe: Candle interval.\n",
    "            start_time: Start of the range.\n",
    "            end_time: End of the range.\n",
    "        \n",
    "        Returns:\n",
    "            List of all OHLCV dictionaries in the range.\n",
    "        \"\"\"\n",
    "        all_klines = []\n",
    "        current_start = start_time\n",
    "        \n",
    "        timeframe_ms = {\n",
    "            \"1m\": 60_000,\n",
    "            \"5m\": 300_000,\n",
    "            \"15m\": 900_000,\n",
    "            \"1h\": 3_600_000,\n",
    "            \"4h\": 14_400_000,\n",
    "            \"1d\": 86_400_000,\n",
    "        }\n",
    "        step = timedelta(milliseconds=timeframe_ms.get(timeframe, 60_000) * 1000)\n",
    "        \n",
    "        while current_start < end_time:\n",
    "            klines = await self.get_klines(\n",
    "                symbol=symbol,\n",
    "                timeframe=timeframe,\n",
    "                start_time=current_start,\n",
    "                end_time=min(current_start + step, end_time),\n",
    "                limit=1000\n",
    "            )\n",
    "            \n",
    "            if not klines:\n",
    "                break\n",
    "            \n",
    "            all_klines.extend(klines)\n",
    "            current_start = klines[-1][\"timestamp\"] + timedelta(milliseconds=1)\n",
    "            await asyncio.sleep(0.05)\n",
    "            \n",
    "            if len(all_klines) % 10000 == 0:\n",
    "                logger.info(f\"{symbol}: loaded {len(all_klines):,} candles...\")\n",
    "        \n",
    "        return all_klines\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SpotStore:\n",
    "    \"\"\"DuckDB storage for OHLCV data.\"\"\"\n",
    "    \n",
    "    db_path: Path\n",
    "    _con: duckdb.DuckDBPyConnection = field(init=False)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self._con = duckdb.connect(str(self.db_path))\n",
    "        self._ensure_tables()\n",
    "    \n",
    "    def _ensure_tables(self):\n",
    "        existing = self._con.execute(\"\"\"\n",
    "            SELECT column_name FROM information_schema.columns \n",
    "            WHERE table_name = 'ohlcv'\n",
    "        \"\"\").fetchall()\n",
    "        existing_cols = {row[0] for row in existing}\n",
    "        \n",
    "        if existing_cols and \"open_time\" in existing_cols:\n",
    "            logger.info(\"Migrating old schema...\")\n",
    "            self._con.execute(\"\"\"\n",
    "                CREATE TABLE ohlcv_new (\n",
    "                    symbol VARCHAR NOT NULL,\n",
    "                    timeframe VARCHAR NOT NULL,\n",
    "                    timestamp TIMESTAMP NOT NULL,\n",
    "                    open DOUBLE NOT NULL,\n",
    "                    high DOUBLE NOT NULL,\n",
    "                    low DOUBLE NOT NULL,\n",
    "                    close DOUBLE NOT NULL,\n",
    "                    volume DOUBLE NOT NULL,\n",
    "                    trades INTEGER,\n",
    "                    PRIMARY KEY (symbol, timeframe, timestamp)\n",
    "                )\n",
    "            \"\"\")\n",
    "            self._con.execute(\"\"\"\n",
    "                INSERT INTO ohlcv_new \n",
    "                SELECT symbol, interval, open_time, open, high, low, close, quote_volume, trades\n",
    "                FROM ohlcv\n",
    "            \"\"\")\n",
    "            self._con.execute(\"DROP TABLE ohlcv\")\n",
    "            self._con.execute(\"ALTER TABLE ohlcv_new RENAME TO ohlcv\")\n",
    "            logger.info(\"Migration complete\")\n",
    "        \n",
    "        self._con.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS ohlcv (\n",
    "                symbol VARCHAR NOT NULL,\n",
    "                timeframe VARCHAR NOT NULL,\n",
    "                timestamp TIMESTAMP NOT NULL,\n",
    "                open DOUBLE NOT NULL,\n",
    "                high DOUBLE NOT NULL,\n",
    "                low DOUBLE NOT NULL,\n",
    "                close DOUBLE NOT NULL,\n",
    "                volume DOUBLE NOT NULL,\n",
    "                trades INTEGER,\n",
    "                PRIMARY KEY (symbol, timeframe, timestamp)\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        self._con.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS idx_ohlcv_symbol_time \n",
    "            ON ohlcv(symbol, timeframe, timestamp DESC)\n",
    "        \"\"\")\n",
    "        \n",
    "        logger.info(f\"Database initialized: {self.db_path}\")\n",
    "    \n",
    "    def insert_klines(self, symbol: str, timeframe: str, klines: list[dict]):\n",
    "        \"\"\"Inserts klines with upsert logic.\n",
    "        \n",
    "        Args:\n",
    "            symbol: Trading pair.\n",
    "            timeframe: Candle interval.\n",
    "            klines: List of OHLCV dictionaries.\n",
    "        \"\"\"\n",
    "        if not klines:\n",
    "            return\n",
    "        \n",
    "        if len(klines) <= 10:\n",
    "            self._con.executemany(\n",
    "                \"INSERT OR REPLACE INTO ohlcv VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "                [\n",
    "                    (symbol, timeframe, k[\"timestamp\"], k[\"open\"], k[\"high\"], \n",
    "                     k[\"low\"], k[\"close\"], k[\"volume\"], k[\"trades\"])\n",
    "                    for k in klines\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            df = pl.DataFrame({\n",
    "                \"symbol\": [symbol] * len(klines),\n",
    "                \"timeframe\": [timeframe] * len(klines),\n",
    "                \"timestamp\": [k[\"timestamp\"] for k in klines],\n",
    "                \"open\": [k[\"open\"] for k in klines],\n",
    "                \"high\": [k[\"high\"] for k in klines],\n",
    "                \"low\": [k[\"low\"] for k in klines],\n",
    "                \"close\": [k[\"close\"] for k in klines],\n",
    "                \"volume\": [k[\"volume\"] for k in klines],\n",
    "                \"trades\": [k[\"trades\"] for k in klines],\n",
    "            })\n",
    "            \n",
    "            self._con.register(\"temp_klines\", df.to_arrow())\n",
    "            self._con.execute(\"INSERT OR REPLACE INTO ohlcv SELECT * FROM temp_klines\")\n",
    "            self._con.unregister(\"temp_klines\")\n",
    "        \n",
    "        logger.debug(f\"Inserted {len(klines):,} rows for {symbol} ({timeframe})\")\n",
    "    \n",
    "    def get_time_bounds(self, symbol: str, timeframe: str) -> tuple[Optional[datetime], Optional[datetime]]:\n",
    "        \"\"\"Returns min and max timestamps for a symbol.\n",
    "        \n",
    "        Args:\n",
    "            symbol: Trading pair.\n",
    "            timeframe: Candle interval.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (min_timestamp, max_timestamp) or (None, None).\n",
    "        \"\"\"\n",
    "        result = self._con.execute(\"\"\"\n",
    "            SELECT MIN(timestamp), MAX(timestamp) FROM ohlcv \n",
    "            WHERE symbol = ? AND timeframe = ?\n",
    "        \"\"\", [symbol, timeframe]).fetchone()\n",
    "        return (result[0], result[1]) if result and result[0] else (None, None)\n",
    "    \n",
    "    def find_gaps(\n",
    "        self,\n",
    "        symbol: str,\n",
    "        timeframe: str,\n",
    "        start: datetime,\n",
    "        end: datetime,\n",
    "        tf_minutes: int\n",
    "    ) -> list[tuple[datetime, datetime]]:\n",
    "        \"\"\"Finds missing data gaps in the specified range.\n",
    "        \n",
    "        Args:\n",
    "            symbol: Trading pair.\n",
    "            timeframe: Candle interval.\n",
    "            start: Start of the range.\n",
    "            end: End of the range.\n",
    "            tf_minutes: Timeframe duration in minutes.\n",
    "        \n",
    "        Returns:\n",
    "            List of (gap_start, gap_end) tuples.\n",
    "        \"\"\"\n",
    "        existing = self._con.execute(\"\"\"\n",
    "            SELECT timestamp FROM ohlcv \n",
    "            WHERE symbol = ? AND timeframe = ? AND timestamp BETWEEN ? AND ?\n",
    "            ORDER BY timestamp\n",
    "        \"\"\", [symbol, timeframe, start, end]).fetchall()\n",
    "        \n",
    "        if not existing:\n",
    "            return [(start, end)]\n",
    "        \n",
    "        existing_times = {row[0] for row in existing}\n",
    "        gaps = []\n",
    "        gap_start = None\n",
    "        current = start\n",
    "        \n",
    "        while current <= end:\n",
    "            if current not in existing_times:\n",
    "                if gap_start is None:\n",
    "                    gap_start = current\n",
    "            else:\n",
    "                if gap_start is not None:\n",
    "                    gaps.append((gap_start, current - timedelta(minutes=tf_minutes)))\n",
    "                    gap_start = None\n",
    "            current += timedelta(minutes=tf_minutes)\n",
    "        \n",
    "        if gap_start is not None:\n",
    "            gaps.append((gap_start, end))\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def load(\n",
    "        self,\n",
    "        symbol: str,\n",
    "        timeframe: str = \"1m\",\n",
    "        hours: Optional[int] = None,\n",
    "        start: Optional[datetime] = None,\n",
    "        end: Optional[datetime] = None,\n",
    "    ) -> pl.DataFrame:\n",
    "        \"\"\"Loads OHLCV data into a Polars DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            symbol: Trading pair.\n",
    "            timeframe: Candle interval.\n",
    "            hours: Load last N hours (alternative to start/end).\n",
    "            start: Start of the range.\n",
    "            end: End of the range.\n",
    "        \n",
    "        Returns:\n",
    "            Polars DataFrame with columns: timestamp, open, high, low, close, volume, trades.\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "            SELECT timestamp, open, high, low, close, volume, trades\n",
    "            FROM ohlcv\n",
    "            WHERE symbol = ? AND timeframe = ?\n",
    "        \"\"\"\n",
    "        params = [symbol, timeframe]\n",
    "        \n",
    "        if hours:\n",
    "            query += f\" AND timestamp > NOW() - INTERVAL '{hours}' HOUR\"\n",
    "        elif start and end:\n",
    "            query += \" AND timestamp BETWEEN ? AND ?\"\n",
    "            params.extend([start, end])\n",
    "        elif start:\n",
    "            query += \" AND timestamp >= ?\"\n",
    "            params.append(start)\n",
    "        elif end:\n",
    "            query += \" AND timestamp <= ?\"\n",
    "            params.append(end)\n",
    "        \n",
    "        query += \" ORDER BY timestamp\"\n",
    "        \n",
    "        return self._con.execute(query, params).pl()\n",
    "    \n",
    "    def get_stats(self) -> pl.DataFrame:\n",
    "        \"\"\"Returns statistics for all pairs in database.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with row counts and time bounds per symbol.\n",
    "        \"\"\"\n",
    "        return self._con.execute(\"\"\"\n",
    "            SELECT \n",
    "                symbol,\n",
    "                timeframe,\n",
    "                COUNT(*) as rows,\n",
    "                MIN(timestamp) as first_candle,\n",
    "                MAX(timestamp) as last_candle,\n",
    "                ROUND(SUM(volume), 2) as total_volume\n",
    "            FROM ohlcv\n",
    "            GROUP BY symbol, timeframe\n",
    "            ORDER BY symbol, timeframe\n",
    "        \"\"\").pl()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Closes the database connection.\"\"\"\n",
    "        self._con.close()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BinanceSpotLoader:\n",
    "    \"\"\"Downloads and stores Binance spot OHLCV data.\"\"\"\n",
    "    \n",
    "    db_path: Path = field(default_factory=lambda: Path(\"raw_data.duckdb\"))\n",
    "    \n",
    "    async def download(\n",
    "        self,\n",
    "        pairs: list[str],\n",
    "        timeframe: str = \"1m\",\n",
    "        days: Optional[int] = None,\n",
    "        start: Optional[datetime] = None,\n",
    "        end: Optional[datetime] = None,\n",
    "        fill_gaps: bool = True,\n",
    "    ):\n",
    "        \"\"\"Downloads historical data for a list of pairs.\n",
    "        \n",
    "        Args:\n",
    "            pairs: List of trading pairs (e.g., ['BTCUSDT', 'ETHUSDT']).\n",
    "            timeframe: Candle interval.\n",
    "            days: Number of days to download (alternative to start/end).\n",
    "            start: Start of the range.\n",
    "            end: End of the range (defaults to now).\n",
    "            fill_gaps: Whether to fill gaps in existing data.\n",
    "        \"\"\"\n",
    "        store = SpotStore(self.db_path)\n",
    "        \n",
    "        now = datetime.now(timezone.utc).replace(tzinfo=None)\n",
    "        \n",
    "        if end is None:\n",
    "            end = now\n",
    "        if start is None:\n",
    "            if days:\n",
    "                start = end - timedelta(days=days)\n",
    "            else:\n",
    "                start = end - timedelta(days=7)\n",
    "        \n",
    "        tf_minutes = {\n",
    "            \"1m\": 1, \"5m\": 5, \"15m\": 15, \n",
    "            \"1h\": 60, \"4h\": 240, \"1d\": 1440\n",
    "        }.get(timeframe, 1)\n",
    "        \n",
    "        async def download_pair(client: BinanceClient, pair: str):\n",
    "            logger.info(f\"Processing {pair} from {start} to {end}\")\n",
    "            \n",
    "            db_min, db_max = store.get_time_bounds(pair, timeframe)\n",
    "            ranges_to_download = []\n",
    "            \n",
    "            if db_min is None:\n",
    "                ranges_to_download.append((start, end))\n",
    "            else:\n",
    "                if start < db_min:\n",
    "                    ranges_to_download.append((start, db_min - timedelta(minutes=tf_minutes)))\n",
    "                \n",
    "                if end > db_max:\n",
    "                    ranges_to_download.append((db_max + timedelta(minutes=tf_minutes), end))\n",
    "                \n",
    "                if fill_gaps:\n",
    "                    overlap_start = max(start, db_min)\n",
    "                    overlap_end = min(end, db_max)\n",
    "                    if overlap_start < overlap_end:\n",
    "                        gaps = store.find_gaps(pair, timeframe, overlap_start, overlap_end, tf_minutes)\n",
    "                        ranges_to_download.extend(gaps)\n",
    "            \n",
    "            for range_start, range_end in ranges_to_download:\n",
    "                if range_start >= range_end:\n",
    "                    continue\n",
    "                    \n",
    "                logger.info(f\"{pair}: downloading {range_start} -> {range_end}\")\n",
    "                \n",
    "                try:\n",
    "                    klines = await client.get_klines_range(\n",
    "                        symbol=pair,\n",
    "                        timeframe=timeframe,\n",
    "                        start_time=range_start,\n",
    "                        end_time=range_end,\n",
    "                    )\n",
    "                    store.insert_klines(pair, timeframe, klines)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error downloading {pair}: {e}\")\n",
    "        \n",
    "        async with BinanceClient() as client:\n",
    "            await asyncio.gather(*[download_pair(client, pair) for pair in pairs])\n",
    "        \n",
    "        logger.info(\"=\" * 60)\n",
    "        print(store.get_stats())\n",
    "        \n",
    "        store.close()\n",
    "    \n",
    "    async def sync(\n",
    "        self,\n",
    "        pairs: list[str],\n",
    "        timeframe: str = \"1m\",\n",
    "        update_interval_sec: int = 60,\n",
    "    ):\n",
    "        \"\"\"Real-time sync that updates latest candles periodically.\n",
    "        \n",
    "        Args:\n",
    "            pairs: List of trading pairs.\n",
    "            timeframe: Candle interval.\n",
    "            update_interval_sec: Seconds between updates.\n",
    "        \"\"\"\n",
    "        store = SpotStore(self.db_path)\n",
    "        \n",
    "        logger.info(f\"Starting real-time sync for {pairs}\")\n",
    "        logger.info(f\"Update interval: {update_interval_sec}s\")\n",
    "        \n",
    "        async def fetch_and_store(client: BinanceClient, pair: str):\n",
    "            try:\n",
    "                klines = await client.get_klines(symbol=pair, timeframe=timeframe, limit=5)\n",
    "                store.insert_klines(pair, timeframe, klines)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error syncing {pair}: {e}\")\n",
    "        \n",
    "        async with BinanceClient() as client:\n",
    "            while True:\n",
    "                await asyncio.gather(*[fetch_and_store(client, pair) for pair in pairs])\n",
    "                logger.debug(f\"Synced {len(pairs)} pairs\")\n",
    "                await asyncio.sleep(update_interval_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = BinanceSpotLoader(db_path=Path(\"raw_data3.duckdb\"))\n",
    "\n",
    "await loader.download(\n",
    "    pairs=[\"BTCUSDT\", \"ETHUSDT\", \"SOLUSDT\", \"XRPUSDT\", \"BNBUSDT\"],\n",
    "    timeframe=\"1m\",\n",
    "    days=10,\n",
    "    fill_gaps=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
