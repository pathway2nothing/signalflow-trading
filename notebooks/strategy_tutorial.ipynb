{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b1c2d3",
   "metadata": {},
   "source": [
    "# Advanced Strategy Components Tutorial\n",
    "\n",
    "This tutorial covers **Phase 2** of SignalFlow's strategy components:\n",
    "\n",
    "1. **Position Sizing** - Flexible capital allocation algorithms\n",
    "2. **Entry Filters** - Pre-trade validation to improve signal quality\n",
    "3. **Signal Aggregation** - Combine signals from multiple detectors\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Signals (from detectors)\n",
    "    |\n",
    "    v\n",
    "[SignalAggregator] -----> Aggregated Signals\n",
    "    |\n",
    "    v\n",
    "SignalEntryRule.check_entries()\n",
    "    |\n",
    "    +---> [EntryFilter(s)] -----> allow_entry() -> bool\n",
    "    |\n",
    "    +---> [PositionSizer] -----> compute_size() -> notional\n",
    "    |\n",
    "    v\n",
    "Order with computed qty\n",
    "```\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Setup](#1-setup)\n",
    "2. [Position Sizing Strategies](#2-position-sizing-strategies)\n",
    "3. [Entry Filters](#3-entry-filters)\n",
    "4. [Signal Aggregation](#4-signal-aggregation)\n",
    "5. [Integration with SignalEntryRule](#5-integration-with-signalentryrule)\n",
    "6. [Grid Trading Example](#6-grid-trading-example)\n",
    "7. [Full Backtest Example](#7-full-backtest-example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import signalflow as sf\n",
    "\n",
    "# Position sizers\n",
    "from signalflow.strategy.component.sizing import (\n",
    "    FixedFractionSizer,\n",
    "    KellyCriterionSizer,\n",
    "    MartingaleSizer,\n",
    "    RiskParitySizer,\n",
    "    SignalContext,\n",
    "    SignalStrengthSizer,\n",
    "    VolatilityTargetSizer,\n",
    ")\n",
    "\n",
    "# Entry filters\n",
    "from signalflow.strategy.component.entry import (\n",
    "    CompositeEntryFilter,\n",
    "    CorrelationFilter,\n",
    "    DrawdownFilter,\n",
    "    PriceDistanceFilter,\n",
    "    RegimeFilter,\n",
    "    SignalAccuracyFilter,\n",
    "    TimeOfDayFilter,\n",
    "    VolatilityFilter,\n",
    ")\n",
    "\n",
    "# Signal aggregation\n",
    "from signalflow.strategy.component.entry import SignalAggregator, VotingMode\n",
    "\n",
    "# Core components\n",
    "from signalflow.core import (\n",
    "    Position,\n",
    "    PositionType,\n",
    "    Signals,\n",
    "    SignalType,\n",
    "    StrategyState,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4f5a6",
   "metadata": {},
   "source": [
    "### Helper: Create Test Environment\n",
    "\n",
    "We'll create a reusable strategy state and signal context for testing components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: cash=$10,000.00\n",
      "Signal: BTCUSDT rise (p=0.8) @ $50,000.00\n"
     ]
    }
   ],
   "source": [
    "def create_test_state(cash: float = 10000.0) -> StrategyState:\n",
    "    \"\"\"Create a test strategy state with specified cash.\"\"\"\n",
    "    state = StrategyState(strategy_id=\"tutorial\")\n",
    "    state.portfolio.cash = cash\n",
    "    return state\n",
    "\n",
    "\n",
    "def create_signal_context(\n",
    "    pair: str = \"BTCUSDT\",\n",
    "    signal_type: str = \"rise\",\n",
    "    probability: float = 0.8,\n",
    "    price: float = 50000.0,\n",
    "    timestamp: datetime = None,\n",
    ") -> SignalContext:\n",
    "    \"\"\"Create a test signal context.\"\"\"\n",
    "    return SignalContext(\n",
    "        pair=pair,\n",
    "        signal_type=signal_type,\n",
    "        probability=probability,\n",
    "        price=price,\n",
    "        timestamp=timestamp or datetime(2024, 1, 1, 10, 0),\n",
    "    )\n",
    "\n",
    "\n",
    "# Test it\n",
    "state = create_test_state(10000.0)\n",
    "signal = create_signal_context()\n",
    "prices = {\"BTCUSDT\": 50000.0, \"ETHUSDT\": 3000.0, \"SOLUSDT\": 100.0}\n",
    "\n",
    "print(f\"State: cash=${state.portfolio.cash:,.2f}\")\n",
    "print(f\"Signal: {signal.pair} {signal.signal_type} (p={signal.probability}) @ ${signal.price:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b7c8",
   "metadata": {},
   "source": [
    "## 2. Position Sizing Strategies\n",
    "\n",
    "Position sizers determine **how much** capital to allocate to each trade. All sizers implement:\n",
    "\n",
    "```python\n",
    "def compute_size(signal: SignalContext, state: StrategyState, prices: dict[str, float]) -> float:\n",
    "    \"\"\"Return notional value (quote currency). 0.0 to skip.\"\"\"\n",
    "```\n",
    "\n",
    "Available sizers:\n",
    "\n",
    "| Sizer | Strategy | Key Params |\n",
    "|-------|----------|------------|\n",
    "| `FixedFractionSizer` | Fixed % of equity | `fraction`, `min_notional`, `max_notional` |\n",
    "| `SignalStrengthSizer` | Scale by probability | `base_size`, `min_probability` |\n",
    "| `KellyCriterionSizer` | Optimal f* formula | `kelly_fraction`, `min_trades_for_stats` |\n",
    "| `VolatilityTargetSizer` | Inverse volatility | `target_volatility`, `default_volatility_pct` |\n",
    "| `RiskParitySizer` | Equal risk budget | `target_positions`, `default_volatility_pct` |\n",
    "| `MartingaleSizer` | Grid/DCA scaling | `base_size`, `multiplier`, `max_grid_levels` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7c8d9",
   "metadata": {},
   "source": [
    "### 2.1 FixedFractionSizer\n",
    "\n",
    "The simplest sizer: allocate a fixed percentage of portfolio equity to each trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8d9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2% of $10,000 = $200.00\n",
      "With max cap: $200.00\n",
      "Below min threshold: $0.00 (skipped)\n"
     ]
    }
   ],
   "source": [
    "# Basic usage: 2% of equity per trade\n",
    "sizer = FixedFractionSizer(fraction=0.02)\n",
    "size = sizer.compute_size(signal, state, prices)\n",
    "print(f\"2% of $10,000 = ${size:,.2f}\")\n",
    "\n",
    "# With min/max constraints\n",
    "sizer_constrained = FixedFractionSizer(\n",
    "    fraction=0.02,\n",
    "    min_notional=50.0,   # Skip if position too small\n",
    "    max_notional=500.0,  # Cap maximum size\n",
    ")\n",
    "size_constrained = sizer_constrained.compute_size(signal, state, prices)\n",
    "print(f\"With max cap: ${size_constrained:,.2f}\")\n",
    "\n",
    "# Too small - returns 0\n",
    "sizer_high_min = FixedFractionSizer(fraction=0.001, min_notional=50.0)\n",
    "size_skip = sizer_high_min.compute_size(signal, state, prices)\n",
    "print(f\"Below min threshold: ${size_skip:,.2f} (skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9e0f1",
   "metadata": {},
   "source": [
    "### 2.2 SignalStrengthSizer\n",
    "\n",
    "Scale position size based on signal probability/confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability 90%: $900.00 \n",
      "Probability 70%: $700.00 \n",
      "Probability 50%: $500.00 \n",
      "Probability 30%: $0.00 (skipped - below min_probability)\n"
     ]
    }
   ],
   "source": [
    "sizer = SignalStrengthSizer(\n",
    "    base_size=1000.0,       # Maximum size at probability=1.0\n",
    "    min_probability=0.5,    # Skip signals below this\n",
    "    max_notional=2000.0,    # Hard cap\n",
    ")\n",
    "\n",
    "# Compare different probability levels\n",
    "for prob in [0.9, 0.7, 0.5, 0.3]:\n",
    "    ctx = create_signal_context(probability=prob)\n",
    "    size = sizer.compute_size(ctx, state, prices)\n",
    "    status = \"\" if size > 0 else \"(skipped - below min_probability)\"\n",
    "    print(f\"Probability {prob:.0%}: ${size:,.2f} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1a2b3",
   "metadata": {},
   "source": [
    "### 2.3 KellyCriterionSizer\n",
    "\n",
    "Uses the Kelly formula to compute optimal position sizing based on edge and payoff ratio:\n",
    "\n",
    "$$f^* = \\frac{p \\cdot b - q}{b}$$\n",
    "\n",
    "Where:\n",
    "- $p$ = win probability\n",
    "- $q$ = loss probability (1 - p)\n",
    "- $b$ = payoff ratio (avg win / avg loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High probability (80%): $2,500.00\n",
      "Low probability (30%): $0.00 (negative Kelly)\n",
      "\n",
      "Kelly calculation: f* = (0.8*1.5 - 0.19999999999999996)/1.5 = 0.667\n",
      "Half-Kelly: 0.333\n",
      "Theoretical max: $3,333.33 (before 25% cap)\n"
     ]
    }
   ],
   "source": [
    "sizer = KellyCriterionSizer(\n",
    "    kelly_fraction=0.5,          # Half-Kelly (more conservative)\n",
    "    use_signal_probability=True, # Use signal.probability as win rate\n",
    "    default_payoff_ratio=1.5,    # Expected win/loss ratio\n",
    "    max_fraction=0.25,           # Never exceed 25% of equity\n",
    "    min_notional=10.0,           # Minimum position size\n",
    ")\n",
    "\n",
    "# With high probability signal\n",
    "ctx_high = create_signal_context(probability=0.8)\n",
    "size_high = sizer.compute_size(ctx_high, state, prices)\n",
    "print(f\"High probability (80%): ${size_high:,.2f}\")\n",
    "\n",
    "# With low probability signal (negative Kelly -> 0)\n",
    "ctx_low = create_signal_context(probability=0.3)\n",
    "size_low = sizer.compute_size(ctx_low, state, prices)\n",
    "print(f\"Low probability (30%): ${size_low:,.2f} (negative Kelly)\")\n",
    "\n",
    "# Kelly formula breakdown:\n",
    "p, b = 0.8, 1.5\n",
    "q = 1 - p\n",
    "kelly_f = (p * b - q) / b\n",
    "half_kelly = kelly_f * 0.5\n",
    "print(f\"\\nKelly calculation: f* = ({p}*{b} - {q})/{b} = {kelly_f:.3f}\")\n",
    "print(f\"Half-Kelly: {half_kelly:.3f}\")\n",
    "print(f\"Theoretical max: ${10000 * half_kelly:,.2f} (before 25% cap)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d5",
   "metadata": {},
   "source": [
    "### 2.4 VolatilityTargetSizer\n",
    "\n",
    "Size positions inversely to volatility to target a constant risk level:\n",
    "\n",
    "$$\\text{notional} = \\frac{\\text{target\\_vol} \\times \\text{equity}}{\\text{asset\\_vol}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low volatility (0.5%): $2,000.00\n",
      "High volatility (5%): $2,000.00\n",
      "No ATR (default 2%): $2,000.00\n"
     ]
    }
   ],
   "source": [
    "sizer = VolatilityTargetSizer(\n",
    "    target_volatility=0.01,      # Target 1% daily volatility exposure\n",
    "    default_volatility_pct=0.02, # Fallback if no ATR data\n",
    "    max_fraction=0.20,           # Max 20% of equity per position\n",
    ")\n",
    "\n",
    "# Low volatility asset -> larger position\n",
    "state_low_vol = create_test_state(10000.0)\n",
    "state_low_vol.runtime[\"atr\"] = {\"BTCUSDT\": 250.0}  # 0.5% of price\n",
    "size_low_vol = sizer.compute_size(signal, state_low_vol, prices)\n",
    "print(f\"Low volatility (0.5%): ${size_low_vol:,.2f}\")\n",
    "\n",
    "# High volatility asset -> smaller position  \n",
    "state_high_vol = create_test_state(10000.0)\n",
    "state_high_vol.runtime[\"atr\"] = {\"BTCUSDT\": 2500.0}  # 5% of price\n",
    "size_high_vol = sizer.compute_size(signal, state_high_vol, prices)\n",
    "print(f\"High volatility (5%): ${size_high_vol:,.2f}\")\n",
    "\n",
    "# No ATR data -> uses default volatility\n",
    "size_default = sizer.compute_size(signal, state, prices)\n",
    "print(f\"No ATR (default 2%): ${size_default:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5e6f7",
   "metadata": {},
   "source": [
    "### 2.5 RiskParitySizer\n",
    "\n",
    "Allocate equal risk budget across a target number of positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk parity size: $1,000.00\n",
      "Max per position: $1,000.00 (equity / target_positions)\n"
     ]
    }
   ],
   "source": [
    "sizer = RiskParitySizer(\n",
    "    target_positions=10,         # Expect to hold ~10 positions\n",
    "    default_volatility_pct=0.02, # Fallback volatility\n",
    ")\n",
    "\n",
    "# With volatility data\n",
    "state_vol = create_test_state(10000.0)\n",
    "state_vol.runtime[\"atr\"] = {\"BTCUSDT\": 500.0}  # 1% of price\n",
    "\n",
    "size = sizer.compute_size(signal, state_vol, prices)\n",
    "print(f\"Risk parity size: ${size:,.2f}\")\n",
    "print(f\"Max per position: ${10000/10:,.2f} (equity / target_positions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7a8b9",
   "metadata": {},
   "source": [
    "### 2.6 MartingaleSizer\n",
    "\n",
    "For grid/DCA strategies: increase position size with each grid level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0: $100.00 \n",
      "Level 1: $150.00 \n",
      "Level 2: $225.00 \n",
      "Level 3: $337.50 \n",
      "Level 4: $506.25 \n",
      "Level 5: $0.00 (max levels reached)\n"
     ]
    }
   ],
   "source": [
    "sizer = MartingaleSizer(\n",
    "    base_size=100.0,      # First entry size\n",
    "    multiplier=1.5,       # Each level is 1.5x previous\n",
    "    max_grid_levels=5,    # Max 5 entries per pair\n",
    "    max_notional=1000.0,  # Hard cap per entry\n",
    ")\n",
    "\n",
    "# Simulate adding grid levels\n",
    "for level in range(6):\n",
    "    state_grid = create_test_state(10000.0)\n",
    "    \n",
    "    # Add existing positions for this pair\n",
    "    for i in range(level):\n",
    "        pos = Position(\n",
    "            pair=\"BTCUSDT\",\n",
    "            position_type=PositionType.LONG,\n",
    "            entry_price=50000.0 - i * 1000,\n",
    "            qty=0.002,\n",
    "        )\n",
    "        state_grid.portfolio.positions[f\"pos_{i}\"] = pos\n",
    "    \n",
    "    size = sizer.compute_size(signal, state_grid, prices)\n",
    "    expected = 100 * (1.5 ** level) if level < 5 else 0\n",
    "    status = \"\" if size > 0 else \"(max levels reached)\"\n",
    "    print(f\"Level {level}: ${size:,.2f} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9c0d1",
   "metadata": {},
   "source": [
    "## 3. Entry Filters\n",
    "\n",
    "Entry filters validate signals before opening positions. All filters implement:\n",
    "\n",
    "```python\n",
    "def allow_entry(signal: SignalContext, state: StrategyState, prices: dict[str, float]) -> tuple[bool, str]:\n",
    "    \"\"\"Return (allowed, reason). Empty reason if allowed.\"\"\"\n",
    "```\n",
    "\n",
    "Available filters:\n",
    "\n",
    "| Filter | Blocks When | Key Params |\n",
    "|--------|-------------|------------|\n",
    "| `RegimeFilter` | Signal doesn't match market regime | N/A |\n",
    "| `VolatilityFilter` | Volatility outside min/max range | `min_volatility`, `max_volatility` |\n",
    "| `DrawdownFilter` | Drawdown exceeds threshold | `max_drawdown`, `recovery_threshold` |\n",
    "| `CorrelationFilter` | Too many correlated positions | `max_correlation`, `max_correlated_positions` |\n",
    "| `TimeOfDayFilter` | Outside trading hours | `allowed_hours`, `blocked_hours` |\n",
    "| `PriceDistanceFilter` | Price too close to existing entry | `min_distance_pct`, `direction_aware` |\n",
    "| `SignalAccuracyFilter` | Detector accuracy below threshold | `min_accuracy`, `min_samples` |\n",
    "| `CompositeEntryFilter` | Combines multiple filters | `filters`, `require_all` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0d1e2",
   "metadata": {},
   "source": [
    "### 3.1 RegimeFilter\n",
    "\n",
    "Only allow signals that match the current market regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1e2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regime: trend_up                  | RISE signal: ALLOWED \n",
      "Regime: trend_down                | RISE signal: BLOCKED regime=trend_down not in ['trend_up', 'mean_reversion_oversold']\n",
      "Regime: mean_reversion_oversold   | RISE signal: ALLOWED \n",
      "Regime: choppy                    | RISE signal: BLOCKED regime=choppy not in ['trend_up', 'mean_reversion_oversold']\n"
     ]
    }
   ],
   "source": [
    "filter_ = RegimeFilter()\n",
    "\n",
    "# Test different regimes\n",
    "regimes = [\"trend_up\", \"trend_down\", \"mean_reversion_oversold\", \"choppy\"]\n",
    "\n",
    "for regime in regimes:\n",
    "    state_regime = create_test_state()\n",
    "    state_regime.runtime[\"regime\"] = {\"BTCUSDT\": regime}\n",
    "    \n",
    "    # RISE signal\n",
    "    ctx_rise = create_signal_context(signal_type=\"rise\")\n",
    "    allowed, reason = filter_.allow_entry(ctx_rise, state_regime, prices)\n",
    "    print(f\"Regime: {regime:25} | RISE signal: {'ALLOWED' if allowed else 'BLOCKED'} {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2f3a4",
   "metadata": {},
   "source": [
    "### 3.2 VolatilityFilter\n",
    "\n",
    "Skip trading when volatility is too low (no opportunity) or too high (too risky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3a4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATR 0.2%: BLOCKED: volatility=0.0020 < min=0.005\n",
      "ATR 1.0%: ALLOWED\n",
      "ATR 5.0%: BLOCKED: volatility=0.0500 > max=0.03\n"
     ]
    }
   ],
   "source": [
    "filter_ = VolatilityFilter(\n",
    "    min_volatility=0.005,  # Need at least 0.5% vol\n",
    "    max_volatility=0.03,   # Max 3% vol\n",
    ")\n",
    "\n",
    "# Test different volatility levels\n",
    "for atr_pct in [0.002, 0.01, 0.05]:\n",
    "    atr = signal.price * atr_pct\n",
    "    state_vol = create_test_state()\n",
    "    state_vol.runtime[\"atr\"] = {\"BTCUSDT\": atr}\n",
    "    \n",
    "    allowed, reason = filter_.allow_entry(signal, state_vol, prices)\n",
    "    status = \"ALLOWED\" if allowed else f\"BLOCKED: {reason}\"\n",
    "    print(f\"ATR {atr_pct:.1%}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a4b5c6",
   "metadata": {},
   "source": [
    "### 3.3 DrawdownFilter\n",
    "\n",
    "Pause trading after significant drawdown until recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5c6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawdown 5%: ALLOWED\n",
      "Drawdown 12%: BLOCKED: drawdown=12.00% >= max=10.00%\n",
      "Drawdown 8%: BLOCKED: paused, drawdown=8.00% > recovery=5.00%\n",
      "Drawdown 4%: ALLOWED\n",
      "Drawdown 6%: ALLOWED\n"
     ]
    }
   ],
   "source": [
    "filter_ = DrawdownFilter(\n",
    "    max_drawdown=0.10,         # Pause at 10% drawdown\n",
    "    recovery_threshold=0.05,   # Resume when back to 5%\n",
    ")\n",
    "\n",
    "# Simulate drawdown cycle\n",
    "drawdown_levels = [0.05, 0.12, 0.08, 0.04, 0.06]\n",
    "\n",
    "for dd in drawdown_levels:\n",
    "    state_dd = create_test_state()\n",
    "    state_dd.metrics[\"current_drawdown\"] = dd\n",
    "    \n",
    "    allowed, reason = filter_.allow_entry(signal, state_dd, prices)\n",
    "    status = \"ALLOWED\" if allowed else f\"BLOCKED: {reason}\"\n",
    "    print(f\"Drawdown {dd:.0%}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d7e8",
   "metadata": {},
   "source": [
    "### 3.4 TimeOfDayFilter\n",
    "\n",
    "Restrict trading to specific hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour 08:00 -> BLOCKED: hour=8 not in allowed hours\n",
      "Hour 10:00 -> ALLOWED\n",
      "Hour 16:00 -> ALLOWED\n",
      "Hour 20:00 -> BLOCKED: hour=20 not in allowed hours\n"
     ]
    }
   ],
   "source": [
    "# Only trade during market hours (9 AM - 4 PM)\n",
    "filter_ = TimeOfDayFilter(allowed_hours=list(range(9, 17)))\n",
    "\n",
    "for hour in [8, 10, 16, 20]:\n",
    "    ctx = create_signal_context(timestamp=datetime(2024, 1, 1, hour, 0))\n",
    "    allowed, reason = filter_.allow_entry(ctx, state, prices)\n",
    "    status = \"ALLOWED\" if allowed else f\"BLOCKED: {reason}\"\n",
    "    print(f\"Hour {hour:02d}:00 -> {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8f9a0",
   "metadata": {},
   "source": [
    "### 3.5 PriceDistanceFilter\n",
    "\n",
    "For grid strategies: only add to position when price has moved enough from last entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing LONG @ $50,000. Testing RISE signals at:\n",
      "  $50,000 (+0.0%): BLOCKED\n",
      "  $49,500 (-1.0%): BLOCKED\n",
      "  $49,000 (-2.0%): ALLOWED\n",
      "  $48,500 (-3.0%): ALLOWED\n",
      "  $51,000 (+2.0%): BLOCKED\n"
     ]
    }
   ],
   "source": [
    "filter_ = PriceDistanceFilter(\n",
    "    min_distance_pct=0.02,   # Need 2% price move\n",
    "    direction_aware=True,    # LONG wants lower price, SHORT wants higher\n",
    ")\n",
    "\n",
    "# Create state with existing position\n",
    "state_pos = create_test_state()\n",
    "pos = Position(\n",
    "    pair=\"BTCUSDT\",\n",
    "    position_type=PositionType.LONG,\n",
    "    entry_price=50000.0,\n",
    "    qty=0.01,\n",
    "    entry_time=datetime(2024, 1, 1, 9, 0),\n",
    ")\n",
    "state_pos.portfolio.positions[pos.id] = pos\n",
    "\n",
    "# Test adding at different prices\n",
    "test_prices = [50000, 49500, 49000, 48500, 51000]\n",
    "\n",
    "print(\"Existing LONG @ $50,000. Testing RISE signals at:\")\n",
    "for p in test_prices:\n",
    "    ctx = create_signal_context(signal_type=\"rise\", price=p)\n",
    "    allowed, reason = filter_.allow_entry(ctx, state_pos, {\"BTCUSDT\": p})\n",
    "    pct_change = (p - 50000) / 50000\n",
    "    status = \"ALLOWED\" if allowed else f\"BLOCKED\"\n",
    "    print(f\"  ${p:,} ({pct_change:+.1%}): {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a0b1c2",
   "metadata": {},
   "source": [
    "### 3.6 SignalAccuracyFilter\n",
    "\n",
    "Track real-time signal accuracy and pause when detector performance drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1c2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 55%, 50 samples: ALLOWED\n",
      "Accuracy 40%, 50 samples: BLOCKED: signal_accuracy=40.00% < min=50.00%\n",
      "Accuracy 30%, 10 samples: ALLOWED\n"
     ]
    }
   ],
   "source": [
    "filter_ = SignalAccuracyFilter(\n",
    "    min_accuracy=0.50,   # Require 50% accuracy\n",
    "    min_samples=20,      # Need 20+ samples for reliable stats\n",
    ")\n",
    "\n",
    "# Test different accuracy scenarios\n",
    "scenarios = [\n",
    "    {\"overall\": 0.55, \"samples\": 50},  # Good accuracy, enough samples\n",
    "    {\"overall\": 0.40, \"samples\": 50},  # Poor accuracy\n",
    "    {\"overall\": 0.30, \"samples\": 10},  # Poor accuracy but not enough samples\n",
    "]\n",
    "\n",
    "for scenario in scenarios:\n",
    "    state_acc = create_test_state()\n",
    "    state_acc.runtime[\"signal_accuracy\"] = {\"BTCUSDT\": scenario}\n",
    "    \n",
    "    allowed, reason = filter_.allow_entry(signal, state_acc, prices)\n",
    "    status = \"ALLOWED\" if allowed else f\"BLOCKED: {reason}\"\n",
    "    print(f\"Accuracy {scenario['overall']:.0%}, {scenario['samples']} samples: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e5",
   "metadata": {},
   "source": [
    "### 3.7 CompositeEntryFilter\n",
    "\n",
    "Combine multiple filters with AND/OR logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario: regime=trend_down (fails), drawdown=5% (passes)\n",
      "\n",
      "require_all=True:  BLOCKED\n",
      "require_all=False: ALLOWED\n"
     ]
    }
   ],
   "source": [
    "# All filters must pass (AND logic)\n",
    "composite_all = CompositeEntryFilter(\n",
    "    filters=[\n",
    "        RegimeFilter(),\n",
    "        DrawdownFilter(max_drawdown=0.10),\n",
    "        TimeOfDayFilter(allowed_hours=list(range(9, 17))),\n",
    "    ],\n",
    "    require_all=True,\n",
    ")\n",
    "\n",
    "# Any filter must pass (OR logic)  \n",
    "composite_any = CompositeEntryFilter(\n",
    "    filters=[\n",
    "        RegimeFilter(),\n",
    "        DrawdownFilter(max_drawdown=0.10),\n",
    "    ],\n",
    "    require_all=False,\n",
    ")\n",
    "\n",
    "# Setup state where regime fails but drawdown passes\n",
    "state_mixed = create_test_state()\n",
    "state_mixed.runtime[\"regime\"] = {\"BTCUSDT\": \"trend_down\"}  # Fails for RISE\n",
    "state_mixed.metrics[\"current_drawdown\"] = 0.05              # Passes\n",
    "\n",
    "ctx = create_signal_context(signal_type=\"rise\", timestamp=datetime(2024, 1, 1, 10, 0))\n",
    "\n",
    "allowed_all, reason_all = composite_all.allow_entry(ctx, state_mixed, prices)\n",
    "allowed_any, reason_any = composite_any.allow_entry(ctx, state_mixed, prices)\n",
    "\n",
    "print(\"Scenario: regime=trend_down (fails), drawdown=5% (passes)\")\n",
    "print(f\"\\nrequire_all=True:  {'ALLOWED' if allowed_all else 'BLOCKED'}\")\n",
    "print(f\"require_all=False: {'ALLOWED' if allowed_any else 'BLOCKED'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4f5a7",
   "metadata": {},
   "source": [
    "## 4. Signal Aggregation\n",
    "\n",
    "Combine signals from multiple detectors using different voting strategies.\n",
    "\n",
    "| Mode | Description |\n",
    "|------|-------------|\n",
    "| `MAJORITY` | Most common signal type wins (with min agreement threshold) |\n",
    "| `WEIGHTED` | Weighted average by probability or custom weights |\n",
    "| `UNANIMOUS` | All detectors must agree |\n",
    "| `ANY` | Any non-NONE signal passes (highest probability wins) |\n",
    "| `META_LABELING` | First detector provides direction, rest validate |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source signals:\n",
      "  Detector 1: RISE p=0.9\n",
      "  Detector 2: RISE p=0.7\n",
      "  Detector 3: FALL p=0.6\n"
     ]
    }
   ],
   "source": [
    "# Create sample signals from different detectors\n",
    "ts = datetime(2024, 1, 1)\n",
    "\n",
    "# Detector 1: High confidence RISE\n",
    "signals_1 = Signals(\n",
    "    pl.DataFrame({\n",
    "        \"pair\": [\"BTCUSDT\"],\n",
    "        \"timestamp\": [ts],\n",
    "        \"signal_type\": [SignalType.RISE.value],\n",
    "        \"signal\": [1],\n",
    "        \"probability\": [0.9],\n",
    "    })\n",
    ")\n",
    "\n",
    "# Detector 2: Medium confidence RISE\n",
    "signals_2 = Signals(\n",
    "    pl.DataFrame({\n",
    "        \"pair\": [\"BTCUSDT\"],\n",
    "        \"timestamp\": [ts],\n",
    "        \"signal_type\": [SignalType.RISE.value],\n",
    "        \"signal\": [1],\n",
    "        \"probability\": [0.7],\n",
    "    })\n",
    ")\n",
    "\n",
    "# Detector 3: FALL signal (disagreement)\n",
    "signals_3 = Signals(\n",
    "    pl.DataFrame({\n",
    "        \"pair\": [\"BTCUSDT\"],\n",
    "        \"timestamp\": [ts],\n",
    "        \"signal_type\": [SignalType.FALL.value],\n",
    "        \"signal\": [-1],\n",
    "        \"probability\": [0.6],\n",
    "    })\n",
    ")\n",
    "\n",
    "print(\"Source signals:\")\n",
    "print(f\"  Detector 1: RISE p=0.9\")\n",
    "print(f\"  Detector 2: RISE p=0.7\")\n",
    "print(f\"  Detector 3: FALL p=0.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a6b7c9",
   "metadata": {},
   "source": [
    "### 4.1 Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7c8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAJORITY (min 50% agreement):\n",
      "  Signal: rise\n",
      "  Probability: 0.80\n",
      "  (2/3 = 67% agree on RISE)\n"
     ]
    }
   ],
   "source": [
    "agg = SignalAggregator(\n",
    "    voting_mode=VotingMode.MAJORITY,\n",
    "    min_agreement=0.5,  # Need 50%+ to agree\n",
    ")\n",
    "\n",
    "result = agg.aggregate([signals_1, signals_2, signals_3])\n",
    "print(f\"MAJORITY (min 50% agreement):\")\n",
    "print(f\"  Signal: {result.value['signal_type'][0]}\")\n",
    "print(f\"  Probability: {result.value['probability'][0]:.2f}\")\n",
    "print(f\"  (2/3 = 67% agree on RISE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c8d9e1",
   "metadata": {},
   "source": [
    "### 4.2 Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTED (probability):\n",
      "  Result: rise p=0.800\n",
      "  Expected: (0.9 + 0.7) / 2 = 0.80\n",
      "\n",
      "WEIGHTED (custom weights 3:1):\n",
      "  Result: rise p=0.850\n",
      "  Expected: (0.9*3 + 0.7*1) / 4 = 0.85\n"
     ]
    }
   ],
   "source": [
    "# Weight by probability (default)\n",
    "agg_prob = SignalAggregator(\n",
    "    voting_mode=VotingMode.WEIGHTED,\n",
    "    probability_threshold=0.5,\n",
    ")\n",
    "\n",
    "# Custom weights (favor detector 1)\n",
    "agg_custom = SignalAggregator(\n",
    "    voting_mode=VotingMode.WEIGHTED,\n",
    "    weights=[3.0, 1.0, 1.0],  # Detector 1 has 3x weight\n",
    "    probability_threshold=0.5,\n",
    ")\n",
    "\n",
    "result_prob = agg_prob.aggregate([signals_1, signals_2])\n",
    "result_custom = agg_custom.aggregate([signals_1, signals_2])\n",
    "\n",
    "print(f\"WEIGHTED (probability):\")\n",
    "print(f\"  Result: {result_prob.value['signal_type'][0]} p={result_prob.value['probability'][0]:.3f}\")\n",
    "print(f\"  Expected: (0.9 + 0.7) / 2 = 0.80\")\n",
    "\n",
    "print(f\"\\nWEIGHTED (custom weights 3:1):\")\n",
    "print(f\"  Result: {result_custom.value['signal_type'][0]} p={result_custom.value['probability'][0]:.3f}\")\n",
    "print(f\"  Expected: (0.9*3 + 0.7*1) / 4 = 0.85\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e0f1a3",
   "metadata": {},
   "source": [
    "### 4.3 Unanimous Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNANIMOUS (2 RISE signals): 1 result(s)\n",
      "UNANIMOUS (RISE + FALL): 0 result(s) (filtered out)\n"
     ]
    }
   ],
   "source": [
    "agg = SignalAggregator(\n",
    "    voting_mode=VotingMode.UNANIMOUS,\n",
    "    probability_threshold=0.0,\n",
    ")\n",
    "\n",
    "# With agreement\n",
    "result_agree = agg.aggregate([signals_1, signals_2])\n",
    "print(f\"UNANIMOUS (2 RISE signals): {result_agree.value.height} result(s)\")\n",
    "\n",
    "# With disagreement\n",
    "result_disagree = agg.aggregate([signals_1, signals_3])\n",
    "print(f\"UNANIMOUS (RISE + FALL): {result_disagree.value.height} result(s) (filtered out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2b3c5",
   "metadata": {},
   "source": [
    "### 4.4 ANY Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANY (RISE p=0.9 vs FALL p=0.6):\n",
      "  Winner: rise (highest probability)\n",
      "  Probability: 0.90\n"
     ]
    }
   ],
   "source": [
    "agg = SignalAggregator(voting_mode=VotingMode.ANY)\n",
    "\n",
    "result = agg.aggregate([signals_1, signals_3])\n",
    "print(f\"ANY (RISE p=0.9 vs FALL p=0.6):\")\n",
    "print(f\"  Winner: {result.value['signal_type'][0]} (highest probability)\")\n",
    "print(f\"  Probability: {result.value['probability'][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4d5e7",
   "metadata": {},
   "source": [
    "### 4.5 Meta-Labeling\n",
    "\n",
    "First detector provides signal direction, subsequent detectors act as validators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META_LABELING:\n",
      "  Detector: RISE p=0.9\n",
      "  Validator: RISE p=0.85\n",
      "  Combined: rise p=0.765\n",
      "  (0.9 * 0.85 = 0.765)\n"
     ]
    }
   ],
   "source": [
    "# Validator confirms the signal\n",
    "validator = Signals(\n",
    "    pl.DataFrame({\n",
    "        \"pair\": [\"BTCUSDT\"],\n",
    "        \"timestamp\": [ts],\n",
    "        \"signal_type\": [SignalType.RISE.value],  # Agrees\n",
    "        \"signal\": [1],\n",
    "        \"probability\": [0.85],  # High confidence\n",
    "    })\n",
    ")\n",
    "\n",
    "agg = SignalAggregator(\n",
    "    voting_mode=VotingMode.META_LABELING,\n",
    "    probability_threshold=0.5,\n",
    ")\n",
    "\n",
    "result = agg.aggregate([signals_1, validator])\n",
    "print(f\"META_LABELING:\")\n",
    "print(f\"  Detector: RISE p=0.9\")\n",
    "print(f\"  Validator: RISE p=0.85\")\n",
    "print(f\"  Combined: {result.value['signal_type'][0]} p={result.value['probability'][0]:.3f}\")\n",
    "print(f\"  (0.9 * 0.85 = 0.765)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6f7a9",
   "metadata": {},
   "source": [
    "## 5. Integration with SignalEntryRule\n",
    "\n",
    "Position sizers and entry filters can be injected into `SignalEntryRule` for seamless integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignalEntryRule configured with:\n",
      "  Position sizer: VolatilityTargetSizer\n",
      "  Entry filters: CompositeEntryFilter\n"
     ]
    }
   ],
   "source": [
    "from signalflow.strategy.component.entry import SignalEntryRule\n",
    "\n",
    "# Create entry rule with custom sizer and filters\n",
    "entry_rule = SignalEntryRule(\n",
    "    # Inject custom position sizer\n",
    "    position_sizer=VolatilityTargetSizer(\n",
    "        target_volatility=0.01,\n",
    "        default_volatility_pct=0.02,\n",
    "        max_fraction=0.15,\n",
    "    ),\n",
    "    \n",
    "    # Inject entry filters\n",
    "    entry_filters=CompositeEntryFilter(\n",
    "        filters=[\n",
    "            DrawdownFilter(max_drawdown=0.15),\n",
    "            VolatilityFilter(max_volatility=0.05),\n",
    "            TimeOfDayFilter(allowed_hours=list(range(8, 22))),\n",
    "        ],\n",
    "        require_all=True,\n",
    "    ),\n",
    "    \n",
    "    # Fallback parameters (used if no sizer provided)\n",
    "    base_position_size=500.0,\n",
    "    min_probability=0.6,\n",
    "    max_positions_per_pair=3,\n",
    "    max_total_positions=10,\n",
    ")\n",
    "\n",
    "print(\"SignalEntryRule configured with:\")\n",
    "print(f\"  Position sizer: {type(entry_rule.position_sizer).__name__}\")\n",
    "print(f\"  Entry filters: {type(entry_rule.entry_filters).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8b9c1",
   "metadata": {},
   "source": [
    "## 6. Grid Trading Example\n",
    "\n",
    "Combine `MartingaleSizer` + `PriceDistanceFilter` for a complete grid trading setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9c0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid trading strategy configured:\n",
      "  Base size: $200\n",
      "  Grid levels: 5 max\n",
      "  Size progression: $200 -> $300 -> $450 -> $675 -> $1012\n",
      "  Min price distance: 2%\n"
     ]
    }
   ],
   "source": [
    "# Grid trading configuration\n",
    "grid_sizer = MartingaleSizer(\n",
    "    base_size=200.0,      # First entry: $200\n",
    "    multiplier=1.5,       # Each level: 1.5x previous\n",
    "    max_grid_levels=5,    # Max 5 entries\n",
    "    max_notional=2000.0,  # Cap at $2000 per entry\n",
    ")\n",
    "\n",
    "grid_filter = CompositeEntryFilter(\n",
    "    filters=[\n",
    "        # Only add if price dropped 2%+ from last entry\n",
    "        PriceDistanceFilter(min_distance_pct=0.02, direction_aware=True),\n",
    "        # Only in favorable regimes\n",
    "        RegimeFilter(),\n",
    "        # Not during high volatility\n",
    "        VolatilityFilter(max_volatility=0.05),\n",
    "    ],\n",
    "    require_all=True,\n",
    ")\n",
    "\n",
    "# Grid entry rule\n",
    "grid_entry_rule = SignalEntryRule(\n",
    "    position_sizer=grid_sizer,\n",
    "    entry_filters=grid_filter,\n",
    "    min_probability=0.5,\n",
    "    max_positions_per_pair=5,  # Allow grid\n",
    ")\n",
    "\n",
    "print(\"Grid trading strategy configured:\")\n",
    "print(f\"  Base size: $200\")\n",
    "print(f\"  Grid levels: 5 max\")\n",
    "print(f\"  Size progression: $200 -> $300 -> $450 -> $675 -> $1012\")\n",
    "print(f\"  Min price distance: 2%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0d1e3",
   "metadata": {},
   "source": [
    "### Simulate Grid Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1e2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating grid entries as price drops:\n",
      "\n",
      "Level 1: BUY @ $50,000 | Size: $200.00 | Qty: 0.004000 BTC\n",
      "Level 2: BUY @ $49,000 | Size: $300.00 | Qty: 0.006122 BTC\n",
      "Level 3: BUY @ $47,500 | Size: $450.00 | Qty: 0.009474 BTC\n",
      "Level 4: BUY @ $46,000 | Size: $675.00 | Qty: 0.014674 BTC\n",
      "Level 5: BUY @ $44,500 | Size: $1,012.50 | Qty: 0.022753 BTC\n",
      "Level 6: SKIP @ $43,000 (max levels reached)\n",
      "\n",
      "============================================================\n",
      "Total positions: 5\n",
      "Total invested: $2,637.50\n",
      "Average entry: $46,253.38\n"
     ]
    }
   ],
   "source": [
    "# Simulate price drops and grid entries\n",
    "entry_prices = [50000, 49000, 47500, 46000, 44500, 43000]\n",
    "\n",
    "state_grid = create_test_state(50000.0)  # $50k capital\n",
    "state_grid.runtime[\"regime\"] = {\"BTCUSDT\": \"trend_up\"}\n",
    "state_grid.runtime[\"atr\"] = {\"BTCUSDT\": 1000.0}  # 2% vol\n",
    "\n",
    "print(\"Simulating grid entries as price drops:\\n\")\n",
    "total_invested = 0\n",
    "positions = []\n",
    "\n",
    "for i, price in enumerate(entry_prices):\n",
    "    ctx = create_signal_context(\n",
    "        signal_type=\"rise\",\n",
    "        probability=0.7,\n",
    "        price=price,\n",
    "    )\n",
    "    \n",
    "    # Check filter\n",
    "    allowed, reason = grid_filter.allow_entry(ctx, state_grid, {\"BTCUSDT\": price})\n",
    "    \n",
    "    if allowed:\n",
    "        # Compute size\n",
    "        size = grid_sizer.compute_size(ctx, state_grid, {\"BTCUSDT\": price})\n",
    "        \n",
    "        if size > 0:\n",
    "            qty = size / price\n",
    "            total_invested += size\n",
    "            \n",
    "            # Add position to state\n",
    "            pos = Position(\n",
    "                pair=\"BTCUSDT\",\n",
    "                position_type=PositionType.LONG,\n",
    "                entry_price=price,\n",
    "                qty=qty,\n",
    "                entry_time=datetime(2024, 1, 1, 10 + i, 0),\n",
    "            )\n",
    "            state_grid.portfolio.positions[pos.id] = pos\n",
    "            positions.append((price, size, qty))\n",
    "            \n",
    "            print(f\"Level {len(positions)}: BUY @ ${price:,} | Size: ${size:,.2f} | Qty: {qty:.6f} BTC\")\n",
    "        else:\n",
    "            print(f\"Level {len(positions)+1}: SKIP @ ${price:,} (max levels reached)\")\n",
    "    else:\n",
    "        print(f\"Attempt @ ${price:,}: BLOCKED - {reason}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total positions: {len(positions)}\")\n",
    "print(f\"Total invested: ${total_invested:,.2f}\")\n",
    "avg_entry = sum(p[0] * p[2] for p in positions) / sum(p[2] for p in positions) if positions else 0\n",
    "print(f\"Average entry: ${avg_entry:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2f3a5",
   "metadata": {},
   "source": [
    "## 7. Full Backtest Example\n",
    "\n",
    "Complete example combining signal aggregation, filters, and sizing in a backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3a4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-06 17:39:39.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msignalflow.data.raw_store.duckdb_stores\u001b[0m:\u001b[36m_ensure_tables\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mDatabase initialized: strategy_tutorial.duckdb (data_type=spot, timeframe=1m)\u001b[0m\n",
      "\u001b[32m2026-02-06 17:39:39.918\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msignalflow.data.raw_store.duckdb_stores\u001b[0m:\u001b[36minsert_klines\u001b[0m:\u001b[36m225\u001b[0m - \u001b[34m\u001b[1mInserted 5,000 rows for BTCUSDT\u001b[0m\n",
      "\u001b[32m2026-02-06 17:39:39.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msignalflow.data.source.virtual\u001b[0m:\u001b[36mdownload\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mVirtualDataProvider: generated 5000 bars for BTCUSDT\u001b[0m\n",
      "\u001b[32m2026-02-06 17:39:39.962\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msignalflow.data.raw_store.duckdb_stores\u001b[0m:\u001b[36minsert_klines\u001b[0m:\u001b[36m225\u001b[0m - \u001b[34m\u001b[1mInserted 5,000 rows for ETHUSDT\u001b[0m\n",
      "\u001b[32m2026-02-06 17:39:39.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msignalflow.data.source.virtual\u001b[0m:\u001b[36mdownload\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mVirtualDataProvider: generated 5000 bars for ETHUSDT\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5000 bars per pair\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from signalflow.data.raw_store import DuckDbRawStore\n",
    "from signalflow.data.source import VirtualDataProvider\n",
    "from signalflow.data import RawDataFactory\n",
    "from signalflow.detector import ExampleSmaCrossDetector\n",
    "\n",
    "# Generate synthetic data\n",
    "PAIRS = [\"BTCUSDT\", \"ETHUSDT\"]\n",
    "N_BARS = 5000\n",
    "START = datetime(2025, 1, 1)\n",
    "\n",
    "spot_store = DuckDbRawStore(db_path=Path(\"strategy_tutorial.duckdb\"), timeframe=\"1m\")\n",
    "\n",
    "provider = VirtualDataProvider(\n",
    "    store=spot_store,\n",
    "    base_prices={\"BTCUSDT\": 50000.0, \"ETHUSDT\": 3000.0},\n",
    "    volatility=0.003,\n",
    "    seed=42,\n",
    ")\n",
    "provider.download(pairs=PAIRS, n_bars=N_BARS, start=START)\n",
    "\n",
    "print(f\"Generated {N_BARS} bars per pair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_data = RawDataFactory.from_duckdb_spot_store(\n",
    "    spot_store_path=Path(\"strategy_tutorial.duckdb\"),\n",
    "    pairs=PAIRS,\n",
    "    start=START,\n",
    "    end=datetime(2025, 1, 4),\n",
    "    data_types=[\"spot\"],\n",
    ")\n",
    "\n",
    "raw_view = sf.RawDataView(raw=raw_data)\n",
    "print(f\"Loaded {raw_view.to_polars('spot').height} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two detectors with different parameters\n",
    "detector_fast = ExampleSmaCrossDetector(fast_period=10, slow_period=30)\n",
    "detector_slow = ExampleSmaCrossDetector(fast_period=20, slow_period=50)\n",
    "\n",
    "# Generate signals\n",
    "signals_fast = detector_fast.run(raw_view)\n",
    "signals_slow = detector_slow.run(raw_view)\n",
    "\n",
    "print(f\"Fast detector signals: {signals_fast.value.filter(pl.col('signal_type') != 'none').height}\")\n",
    "print(f\"Slow detector signals: {signals_slow.value.filter(pl.col('signal_type') != 'none').height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate signals - require both detectors to agree\n",
    "agg = SignalAggregator(\n",
    "    voting_mode=VotingMode.UNANIMOUS,\n",
    "    probability_threshold=0.0,\n",
    ")\n",
    "\n",
    "aggregated_signals = agg.aggregate([signals_fast, signals_slow])\n",
    "active_signals = aggregated_signals.value.filter(pl.col(\"signal_type\") != \"none\")\n",
    "\n",
    "print(f\"\\nAfter UNANIMOUS aggregation: {active_signals.height} signals\")\n",
    "print(f\"  Rise: {active_signals.filter(pl.col('signal_type') == 'rise').height}\")\n",
    "print(f\"  Fall: {active_signals.filter(pl.col('signal_type') == 'fall').height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from signalflow.strategy.broker import BacktestBroker\n",
    "from signalflow.strategy.broker.executor import VirtualSpotExecutor\n",
    "from signalflow.data.strategy_store import DuckDbStrategyStore\n",
    "from signalflow.strategy.runner import OptimizedBacktestRunner\n",
    "from signalflow.strategy.component.exit import TakeProfitStopLossExit\n",
    "from signalflow.analytic.strategy import (\n",
    "    TotalReturnMetric,\n",
    "    DrawdownMetric,\n",
    "    WinRateMetric,\n",
    ")\n",
    "\n",
    "INITIAL_CAPITAL = 10_000.0\n",
    "\n",
    "# Strategy store\n",
    "strategy_store = DuckDbStrategyStore(\"strategy_tutorial_results.duckdb\")\n",
    "strategy_store.init()\n",
    "\n",
    "# Executor and broker\n",
    "executor = VirtualSpotExecutor(fee_rate=0.001, slippage_pct=0.001)\n",
    "broker = BacktestBroker(executor=executor, store=strategy_store)\n",
    "\n",
    "# Entry rule with volatility-based sizing and filters\n",
    "entry_rule = SignalEntryRule(\n",
    "    position_sizer=VolatilityTargetSizer(\n",
    "        target_volatility=0.015,\n",
    "        default_volatility_pct=0.02,\n",
    "        max_fraction=0.15,\n",
    "    ),\n",
    "    entry_filters=CompositeEntryFilter(\n",
    "        filters=[\n",
    "            DrawdownFilter(max_drawdown=0.10),\n",
    "            TimeOfDayFilter(allowed_hours=list(range(6, 22))),\n",
    "        ],\n",
    "        require_all=True,\n",
    "    ),\n",
    "    min_probability=0.0,\n",
    "    max_positions_per_pair=1,\n",
    "    max_total_positions=5,\n",
    "    allow_shorts=False,\n",
    ")\n",
    "\n",
    "# Exit rule\n",
    "exit_rule = TakeProfitStopLossExit(\n",
    "    take_profit_pct=0.02,\n",
    "    stop_loss_pct=0.015,\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "metrics = [\n",
    "    TotalReturnMetric(initial_capital=INITIAL_CAPITAL),\n",
    "    DrawdownMetric(),\n",
    "    WinRateMetric(),\n",
    "]\n",
    "\n",
    "print(\"Backtest configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest\n",
    "runner = OptimizedBacktestRunner(\n",
    "    strategy_id=\"strategy_tutorial\",\n",
    "    broker=broker,\n",
    "    entry_rules=[entry_rule],\n",
    "    exit_rules=[exit_rule],\n",
    "    metrics=metrics,\n",
    "    initial_capital=INITIAL_CAPITAL,\n",
    "    data_key=\"spot\",\n",
    ")\n",
    "\n",
    "# Use aggregated signals with probability column added\n",
    "final_state = runner.run(raw_data, aggregated_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runner.get_results()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"BACKTEST RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Initial Capital:  ${INITIAL_CAPITAL:,.2f}\")\n",
    "print(f\"  Final Equity:     ${results.get('final_equity', 0):,.2f}\")\n",
    "print(f\"  Total Return:     {results.get('final_return', 0) * 100:.2f}%\")\n",
    "print(f\"  Max Drawdown:     {results.get('max_drawdown', 0) * 100:.2f}%\")\n",
    "print(f\"  Win Rate:         {results.get('win_rate', 0) * 100:.1f}%\")\n",
    "print(f\"  Total Trades:     {results.get('total_trades', 0)}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "spot_store.close()\n",
    "strategy_store.close()\n",
    "\n",
    "# Optionally remove tutorial databases:\n",
    "# Path(\"strategy_tutorial.duckdb\").unlink(missing_ok=True)\n",
    "# Path(\"strategy_tutorial_results.duckdb\").unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1c2d5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered:\n",
    "\n",
    "1. **Position Sizing Strategies**\n",
    "   - `FixedFractionSizer`: Fixed % of equity\n",
    "   - `SignalStrengthSizer`: Scale by probability\n",
    "   - `KellyCriterionSizer`: Optimal f* formula\n",
    "   - `VolatilityTargetSizer`: Inverse volatility\n",
    "   - `RiskParitySizer`: Equal risk budget\n",
    "   - `MartingaleSizer`: Grid/DCA scaling\n",
    "\n",
    "2. **Entry Filters**\n",
    "   - `RegimeFilter`: Match market regime\n",
    "   - `VolatilityFilter`: Volatility range\n",
    "   - `DrawdownFilter`: Pause on drawdown\n",
    "   - `TimeOfDayFilter`: Trading hours\n",
    "   - `PriceDistanceFilter`: Grid spacing\n",
    "   - `SignalAccuracyFilter`: Detector performance\n",
    "   - `CompositeEntryFilter`: AND/OR logic\n",
    "\n",
    "3. **Signal Aggregation**\n",
    "   - `MAJORITY`: Most common wins\n",
    "   - `WEIGHTED`: Probability-weighted\n",
    "   - `UNANIMOUS`: All must agree\n",
    "   - `ANY`: Highest probability\n",
    "   - `META_LABELING`: Detector + validator\n",
    "\n",
    "4. **Integration**\n",
    "   - Injectable components in `SignalEntryRule`\n",
    "   - Grid trading example\n",
    "   - Full backtest with all components"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
